import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.fft import fft, fftfreq
from scipy.signal import find_peaks, butter, filtfilt, hilbert, savgol_filter
from scipy.interpolate import interp1d
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨äºæ˜¾ç¤ºä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False  # ç”¨äºæ˜¾ç¤ºè´Ÿå·

class EnhancedXAxisNystagmusAnalyzer:
    def __init__(self, file_path, fps=60):                                          
        """
        å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æå™¨
        
        Args:
            file_path (str): åŒ…å«é¢„æµ‹æ•°æ®çš„CSVæ–‡ä»¶è·¯å¾„
            fps (int): è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤60fps
        """
        self.file_path = file_path
        self.fps = fps
        self.data = None
        self.nystagmus_analysis = {}
        self.reduction_analysis = {}
        self.trajectory_analysis = {}  # æ–°å¢ï¼šè½¨è¿¹åˆ†æç»“æœ
        self.reference_point = None 
        self.load_data()
        
    def load_data(self):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            if self.file_path.endswith('.csv'):
                self.data = pd.read_csv(self.file_path)
            else:
                self.data = pd.read_excel(self.file_path)                                                 
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_columns = ['frameId', 'actualX', 'predictedX']                                                        
            missing_columns = [col for col in required_columns if col not in self.data.columns]
            if missing_columns:
                print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                self.data = None
                return
            
            # ç§»é™¤æ— æ•ˆæ•°æ®ï¼ˆactualXä¸ºNAæˆ–0çš„è¡Œï¼‰
            self.data = self.data.dropna(subset=['actualX', 'predictedX'])
            self.data = self.data[self.data['actualX'] != 0]
            
            # é‡ç½®ç´¢å¼•
            self.data.reset_index(drop=True, inplace=True)
            
            # ä½¿ç”¨frameIdä½œä¸ºåºåˆ—å·
            self.data['åºåˆ—å·'] = self.data['frameId']
            
            # æ·»åŠ æ—¶é—´åˆ—ï¼ˆç§’ï¼‰
            self.data['æ—¶é—´_ç§’'] = self.data['frameId'] / self.fps
            
            # å¦‚æœæ²¡æœ‰è¯¯å·®åˆ—ï¼Œè®¡ç®—å®ƒä»¬
            if 'predictionErrorX' not in self.data.columns:
                self.data['predictionErrorX'] = self.data['actualX'] - self.data['predictedX']
            if 'errorMagnitude' not in self.data.columns:
                self.data['errorMagnitude'] = np.sqrt(
                    self.data['predictionErrorX']**2 + 
                    self.data.get('predictionErrorY', 0)**2
                )
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.data)} è¡Œæœ‰æ•ˆæ•°æ®")
            print(f"ğŸ“Š æ•°æ®åŒ…å«çš„åˆ—: {list(self.data.columns)}")
            
            # å¿«é€Ÿæ•°æ®æ¦‚è§ˆ
            print(f"\nğŸ“ Xè½´åæ ‡èŒƒå›´:")
            print(f"   çœŸå®æ³¨è§†ç‚¹ X: [{self.data['actualX'].min():.1f}, {self.data['actualX'].max():.1f}]")
            print(f"   é¢„æµ‹æ³¨è§†ç‚¹ X: [{self.data['predictedX'].min():.1f}, {self.data['predictedX'].max():.1f}]")
            print(f"   å¸§IDèŒƒå›´: [{self.data['frameId'].min()}, {self.data['frameId'].max()}]")
            
            # å¦‚æœæœ‰errorMagnitudeåˆ—ï¼Œæ˜¾ç¤ºé¢„æµ‹è¯¯å·®ç»Ÿè®¡
            if 'errorMagnitude' in self.data.columns:
                print(f"\nğŸ“Š é¢„æµ‹è¯¯å·®åˆæ­¥ç»Ÿè®¡:")
                print(f"   å¹³å‡è¯¯å·®: {self.data['errorMagnitude'].mean():.2f} åƒç´ ")
                print(f"   æœ€å¤§è¯¯å·®: {self.data['errorMagnitude'].max():.2f} åƒç´ ")
                print(f"   ä¸­ä½æ•°è¯¯å·®: {self.data['errorMagnitude'].median():.2f} åƒç´ ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            self.data = None

    def analyze_nystagmus_trajectory_characteristics(self):
        """æ·±åº¦åˆ†æXè½´çœ¼éœ‡è½¨è¿¹ç‰¹æ€§"""
        if self.data is None:
            return
        
        print(f"\nğŸ” æ·±åº¦Xè½´çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æ (åŸºäº{self.fps}fpsæ•°æ®):")
        print("="*80)
        
        # è®¡ç®—çœ¼åŠ¨é€Ÿåº¦å’ŒåŠ é€Ÿåº¦
        dt = 1.0 / self.fps
        actual_x = self.data['actualX'].values
        
        # ä½¿ç”¨Savitzky-Golayæ»¤æ³¢å¹³æ»‘æ•°æ®ï¼Œå‡å°‘å™ªå£°
        if len(actual_x) > 5:
            smooth_x = savgol_filter(actual_x, window_length=min(5, len(actual_x)), polyorder=2)
        else:
            smooth_x = actual_x
        
        # è®¡ç®—é€Ÿåº¦ï¼ˆåƒç´ /ç§’ï¼‰
        vx = np.gradient(smooth_x, dt)
        speed = np.abs(vx)
        
        # è®¡ç®—åŠ é€Ÿåº¦
        ax = np.gradient(vx, dt)
        acceleration = np.abs(ax)
        
        # å­˜å‚¨åˆ†æç»“æœ
        self.data['é€Ÿåº¦_X'] = vx
        self.data['å¹³æ»‘_X'] = smooth_x
        self.data['Xè½´çœ¼åŠ¨é€Ÿåº¦'] = speed
        self.data['Xè½´åŠ é€Ÿåº¦'] = acceleration
        
        # 1. çœ¼éœ‡ç±»å‹åˆ†æ
        self.analyze_nystagmus_type()
        
        # 2. çœ¼éœ‡æ¨¡å¼è¯†åˆ«
        self.analyze_nystagmus_pattern()
        
        # 3. çœ¼éœ‡é¢‘ç‡æ·±åº¦åˆ†æ
        self.analyze_nystagmus_frequency_enhanced()
        
        # 4. çœ¼éœ‡å¼ºåº¦å’Œç¨³å®šæ€§åˆ†æ
        self.analyze_nystagmus_intensity_enhanced()
        
        # 5. çœ¼éœ‡æ³¢å½¢ç‰¹å¾åˆ†æ
        self.analyze_nystagmus_waveform()
        
        # 6. çœ¼éœ‡æ–¹å‘æ€§åˆ†æ
        self.analyze_nystagmus_directionality()
        
    def analyze_nystagmus_type(self):
        """åˆ†æçœ¼éœ‡ç±»å‹"""
        print(f"\nğŸ¯ çœ¼éœ‡ç±»å‹åˆ†æ:")
        
        actual_x = self.data['actualX'].values
        speed = self.data['Xè½´çœ¼åŠ¨é€Ÿåº¦'].values
        
        # è®¡ç®—è¿åŠ¨èŒƒå›´å’Œå˜å¼‚ç³»æ•°
        x_range = np.max(actual_x) - np.min(actual_x)
        x_std = np.std(actual_x)
        x_cv = x_std / np.mean(np.abs(actual_x)) if np.mean(np.abs(actual_x)) > 0 else 0
        
        # è®¡ç®—é€Ÿåº¦åˆ†å¸ƒç‰¹å¾
        speed_mean = np.mean(speed)
        speed_std = np.std(speed)
        high_speed_ratio = np.sum(speed > speed_mean + 2*speed_std) / len(speed)
        
        # çœ¼éœ‡ç±»å‹åˆ¤å®š
        nystagmus_type = []
        
        # åŸºäºè¿åŠ¨å¹…åº¦åˆ†ç±»
        if x_range < 20:
            amplitude_type = "å¾®å¹…çœ¼éœ‡"
        elif x_range < 50:
            amplitude_type = "å°å¹…çœ¼éœ‡"
        elif x_range < 100:
            amplitude_type = "ä¸­å¹…çœ¼éœ‡"
        else:
            amplitude_type = "å¤§å¹…çœ¼éœ‡"
        
        # åŸºäºé€Ÿåº¦ç‰¹å¾åˆ†ç±»
        if speed_mean < 50:
            velocity_type = "æ…¢é€Ÿçœ¼éœ‡"
        elif speed_mean < 200:
            velocity_type = "ä¸­é€Ÿçœ¼éœ‡"
        else:
            velocity_type = "å¿«é€Ÿçœ¼éœ‡"
        
        # åŸºäºè§„å¾‹æ€§åˆ†ç±»
        if x_cv < 0.3:
            regularity_type = "è§„å¾‹æ€§çœ¼éœ‡"
        elif x_cv < 0.6:
            regularity_type = "åŠè§„å¾‹æ€§çœ¼éœ‡"
        else:
            regularity_type = "ä¸è§„å¾‹çœ¼éœ‡"
        
        nystagmus_type = [amplitude_type, velocity_type, regularity_type]
        
        print(f"   â€¢ å¹…åº¦åˆ†ç±»: {amplitude_type} (èŒƒå›´: {x_range:.1f}px)")
        print(f"   â€¢ é€Ÿåº¦åˆ†ç±»: {velocity_type} (å¹³å‡: {speed_mean:.1f}px/s)")
        print(f"   â€¢ è§„å¾‹æ€§: {regularity_type} (å˜å¼‚ç³»æ•°: {x_cv:.3f})")
        print(f"   â€¢ é«˜é€Ÿè¿åŠ¨æ¯”ä¾‹: {high_speed_ratio*100:.1f}%")
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_analysis['çœ¼éœ‡ç±»å‹'] = nystagmus_type
        self.trajectory_analysis['è¿åŠ¨èŒƒå›´'] = x_range
        self.trajectory_analysis['å˜å¼‚ç³»æ•°'] = x_cv
        self.trajectory_analysis['å¹³å‡é€Ÿåº¦'] = speed_mean
        self.trajectory_analysis['é«˜é€Ÿæ¯”ä¾‹'] = high_speed_ratio
        
    def analyze_nystagmus_pattern(self):
        """åˆ†æçœ¼éœ‡æ¨¡å¼ï¼ˆæ‘†åŠ¨æ€§ã€å†²åŠ¨æ€§ã€æ··åˆæ€§ï¼‰"""
        print(f"\nğŸŒŠ çœ¼éœ‡æ¨¡å¼è¯†åˆ«:")
        
        actual_x = self.data['actualX'].values
        vx = self.data['é€Ÿåº¦_X'].values
        
        # æ£€æµ‹é€Ÿåº¦æ–¹å‘å˜åŒ–
        velocity_changes = np.diff(np.sign(vx))
        direction_changes = np.sum(np.abs(velocity_changes) > 0)
        change_frequency = direction_changes / (len(actual_x) / self.fps)  # æ¬¡/ç§’
        
        # æ£€æµ‹å¿«ç›¸å’Œæ…¢ç›¸
        speed = np.abs(vx)
        speed_threshold = np.percentile(speed, 75)  # 75åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
        
        fast_phases = speed > speed_threshold
        slow_phases = speed <= speed_threshold
        
        fast_phase_ratio = np.sum(fast_phases) / len(speed)
        slow_phase_ratio = np.sum(slow_phases) / len(speed)
        
        # åˆ†æé€Ÿåº¦åˆ†å¸ƒçš„åŒå³°æ€§
        from scipy.stats import kurtosis, skew
        speed_kurtosis = kurtosis(speed)
        speed_skewness = skew(speed)
        
        # æ¨¡å¼åˆ¤å®š
        if change_frequency > 3 and fast_phase_ratio > 0.3:
            if speed_kurtosis > 0 and abs(speed_skewness) > 0.5:
                pattern_type = "å†²åŠ¨æ€§çœ¼éœ‡"
                pattern_description = "æ˜æ˜¾çš„å¿«ç›¸-æ…¢ç›¸äº¤æ›¿æ¨¡å¼"
            else:
                pattern_type = "æ‘†åŠ¨æ€§çœ¼éœ‡"
                pattern_description = "è§„å¾‹çš„å¾€å¤æ‘†åŠ¨æ¨¡å¼"
        elif change_frequency > 1.5:
            pattern_type = "æ··åˆæ€§çœ¼éœ‡"
            pattern_description = "æ‘†åŠ¨æ€§å’Œå†²åŠ¨æ€§ç‰¹å¾å¹¶å­˜"
        elif change_frequency < 0.5:
            pattern_type = "æ¼‚ç§»æ€§çœ¼éœ‡"
            pattern_description = "ç¼“æ…¢å•å‘æ¼‚ç§»ä¸ºä¸»"
        else:
            pattern_type = "ä¸è§„åˆ™çœ¼éœ‡"
            pattern_description = "æ— æ˜æ˜¾æ¨¡å¼ç‰¹å¾"
        
        print(f"   â€¢ æ¨¡å¼ç±»å‹: {pattern_type}")
        print(f"   â€¢ ç‰¹å¾æè¿°: {pattern_description}")
        print(f"   â€¢ æ–¹å‘å˜åŒ–é¢‘ç‡: {change_frequency:.2f} æ¬¡/ç§’")
        print(f"   â€¢ å¿«ç›¸æ¯”ä¾‹: {fast_phase_ratio*100:.1f}%")
        print(f"   â€¢ æ…¢ç›¸æ¯”ä¾‹: {slow_phase_ratio*100:.1f}%")
        print(f"   â€¢ é€Ÿåº¦åˆ†å¸ƒå³°åº¦: {speed_kurtosis:.3f}")
        print(f"   â€¢ é€Ÿåº¦åˆ†å¸ƒååº¦: {speed_skewness:.3f}")
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_analysis['çœ¼éœ‡æ¨¡å¼'] = pattern_type
        self.trajectory_analysis['æ¨¡å¼æè¿°'] = pattern_description
        self.trajectory_analysis['æ–¹å‘å˜åŒ–é¢‘ç‡'] = change_frequency
        self.trajectory_analysis['å¿«ç›¸æ¯”ä¾‹'] = fast_phase_ratio
        self.trajectory_analysis['æ…¢ç›¸æ¯”ä¾‹'] = slow_phase_ratio
        
    def analyze_nystagmus_frequency_enhanced(self):
        """å¢å¼ºç‰ˆçœ¼éœ‡é¢‘ç‡åˆ†æ"""
        print(f"\nğŸ“¡ å¢å¼ºç‰ˆé¢‘ç‡åˆ†æ:")
        
        signal = self.data['å¹³æ»‘_X'].values
        
        # å»é™¤è¶‹åŠ¿ï¼ˆå»å‡å€¼ï¼‰
        signal = signal - np.mean(signal)
        
        # åº”ç”¨æ±‰å®çª—
        window = np.hanning(len(signal))
        signal_windowed = signal * window
        
        # FFTåˆ†æ
        fft_result = fft(signal_windowed)
        freqs = fftfreq(len(signal), 1/self.fps)
        
        # åªè€ƒè™‘æ­£é¢‘ç‡
        positive_freqs = freqs[freqs > 0]
        fft_magnitude = np.abs(fft_result[freqs > 0])
        
        # åŠŸç‡è°±å¯†åº¦
        power_spectrum = fft_magnitude ** 2
        
        # åœ¨çœ¼éœ‡å…¸å‹é¢‘ç‡èŒƒå›´å†…å¯»æ‰¾å³°å€¼ (0.2-20Hz)
        nystagmus_freq_range = (positive_freqs >= 0.2) & (positive_freqs <= 20)
        if np.any(nystagmus_freq_range):
            valid_freqs = positive_freqs[nystagmus_freq_range]
            valid_magnitudes = fft_magnitude[nystagmus_freq_range]
            valid_power = power_spectrum[nystagmus_freq_range]
            
            # å¯»æ‰¾æ‰€æœ‰æ˜¾è‘—å³°å€¼
            prominence_threshold = np.max(valid_magnitudes) * 0.2
            peaks, properties = find_peaks(valid_magnitudes, 
                                         prominence=prominence_threshold,
                                         distance=int(0.5 * self.fps / np.mean(np.diff(freqs[freqs > 0]))))
            
            if len(peaks) > 0:
                # ä¸»é¢‘ç‡ï¼ˆæœ€é«˜å³°å€¼ï¼‰
                main_peak_idx = peaks[np.argmax(valid_magnitudes[peaks])]
                main_freq = valid_freqs[main_peak_idx]
                main_power = valid_power[main_peak_idx]
                
                print(f"   â€¢ ä¸»é¢‘ç‡: {main_freq:.3f} Hz (åŠŸç‡: {main_power:.0f})")
                
                # é¢‘ç‡ç¨³å®šæ€§åˆ†æ
                freq_stability = self.analyze_frequency_stability(signal)
                
                # é¢‘ç‡åˆ†ç±»
                freq_category = self.classify_nystagmus_frequency(main_freq)
                print(f"   â€¢ é¢‘ç‡åˆ†ç±»: {freq_category}")
                print(f"   â€¢ é¢‘ç‡ç¨³å®šæ€§: {freq_stability:.3f}")
                
                # æŸ¥æ‰¾è°æ³¢
                harmonics = []
                for i in range(2, 6):  # æ£€æŸ¥2-5æ¬¡è°æ³¢
                    harmonic_freq = main_freq * i
                    if harmonic_freq <= 20:
                        # åœ¨è°æ³¢é¢‘ç‡é™„è¿‘æŸ¥æ‰¾å³°å€¼
                        harmonic_range = np.abs(valid_freqs - harmonic_freq) < 0.5
                        if np.any(harmonic_range):
                            harmonic_power = np.max(valid_power[harmonic_range])
                            if harmonic_power > main_power * 0.1:  # è‡³å°‘æ˜¯ä¸»å³°çš„10%
                                harmonics.append((harmonic_freq, harmonic_power))
                
                if harmonics:
                    print(f"   â€¢ æ£€æµ‹åˆ°è°æ³¢: {len(harmonics)}ä¸ª")
                    for i, (freq, power) in enumerate(harmonics[:3]):
                        print(f"     - {i+2}æ¬¡è°æ³¢: {freq:.2f} Hz (åŠŸç‡: {power:.0f})")
                
                # æ¬¡è¦é¢‘ç‡
                if len(peaks) > 1:
                    sorted_peaks = peaks[np.argsort(valid_magnitudes[peaks])[::-1]]
                    secondary_frequencies = []
                    for peak in sorted_peaks[1:4]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ¬¡è¦é¢‘ç‡
                        sec_freq = valid_freqs[peak]
                        sec_power = valid_power[peak]
                        if sec_power > main_power * 0.3:  # è‡³å°‘æ˜¯ä¸»å³°çš„30%
                            secondary_frequencies.append((sec_freq, sec_power))
                    
                    if secondary_frequencies:
                        print(f"   â€¢ æ¬¡è¦é¢‘ç‡:")
                        for freq, power in secondary_frequencies:
                            print(f"     - {freq:.3f} Hz (åŠŸç‡: {power:.0f})")
                
                # é¢‘å¸¦èƒ½é‡åˆ†æ
                self.analyze_frequency_bands(valid_freqs, valid_power)
                
                # å­˜å‚¨ç»“æœ
                self.trajectory_analysis['ä¸»é¢‘ç‡'] = main_freq
                self.trajectory_analysis['ä¸»é¢‘ç‡åŠŸç‡'] = main_power
                self.trajectory_analysis['é¢‘ç‡ç¨³å®šæ€§'] = freq_stability
                self.trajectory_analysis['é¢‘ç‡åˆ†ç±»'] = freq_category
                self.trajectory_analysis['è°æ³¢æ•°é‡'] = len(harmonics)
                self.trajectory_analysis['æ¬¡è¦é¢‘ç‡æ•°é‡'] = len(secondary_frequencies) if len(peaks) > 1 else 0
                
            else:
                print(f"   â€¢ æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„çœ¼éœ‡é¢‘ç‡å³°å€¼")
                self.trajectory_analysis['ä¸»é¢‘ç‡'] = 0
                self.trajectory_analysis['é¢‘ç‡åˆ†ç±»'] = "æ— æ˜æ˜¾é¢‘ç‡ç‰¹å¾"
        else:
            print(f"   â€¢ é¢‘ç‡åˆ†æï¼šä¿¡å·è¶…å‡ºçœ¼éœ‡å…¸å‹é¢‘ç‡èŒƒå›´")
            
    def analyze_frequency_stability(self, signal):
        """åˆ†æé¢‘ç‡ç¨³å®šæ€§"""
        # ä½¿ç”¨çŸ­æ—¶å‚…é‡Œå¶å˜æ¢åˆ†æé¢‘ç‡éšæ—¶é—´çš„å˜åŒ–
        window_size = min(int(self.fps * 2), len(signal) // 4)  # 2ç§’çª—å£æˆ–1/4ä¿¡å·é•¿åº¦
        
        if window_size < 10:
            return 0.0
            
        step_size = window_size // 2
        main_freqs = []
        
        for i in range(0, len(signal) - window_size, step_size):
            window_signal = signal[i:i+window_size]
            window_signal = window_signal - np.mean(window_signal)
            
            fft_result = fft(window_signal)
            freqs = fftfreq(len(window_signal), 1/self.fps)
            
            positive_freqs = freqs[freqs > 0]
            fft_magnitude = np.abs(fft_result[freqs > 0])
            
            freq_range = (positive_freqs >= 0.2) & (positive_freqs <= 20)
            if np.any(freq_range):
                valid_freqs = positive_freqs[freq_range]
                valid_magnitudes = fft_magnitude[freq_range]
                
                if len(valid_magnitudes) > 0:
                    main_freq_idx = np.argmax(valid_magnitudes)
                    main_freqs.append(valid_freqs[main_freq_idx])
        
        if len(main_freqs) > 1:
            freq_stability = 1 - (np.std(main_freqs) / np.mean(main_freqs))
            return max(0, min(1, freq_stability))
        else:
            return 0.0
    
    def classify_nystagmus_frequency(self, freq):
        """å¯¹çœ¼éœ‡é¢‘ç‡è¿›è¡Œåˆ†ç±»"""
        if freq < 0.5:
            return "è¶…ä½é¢‘çœ¼éœ‡ (<0.5Hz)"
        elif freq < 1.5:
            return "ä½é¢‘çœ¼éœ‡ (0.5-1.5Hz)"
        elif freq < 3:
            return "ä¸­ä½é¢‘çœ¼éœ‡ (1.5-3Hz)"
        elif freq < 5:
            return "ä¸­é¢‘çœ¼éœ‡ (3-5Hz)"
        elif freq < 8:
            return "ä¸­é«˜é¢‘çœ¼éœ‡ (5-8Hz)"
        elif freq < 12:
            return "é«˜é¢‘çœ¼éœ‡ (8-12Hz)"
        else:
            return "è¶…é«˜é¢‘çœ¼éœ‡ (>12Hz)"
    
    def analyze_frequency_bands(self, freqs, power):
        """åˆ†æä¸åŒé¢‘å¸¦çš„èƒ½é‡åˆ†å¸ƒ"""
        bands = {
            "è¶…ä½é¢‘ (<1Hz)": (0, 1),
            "ä½é¢‘ (1-3Hz)": (1, 3),
            "ä¸­é¢‘ (3-7Hz)": (3, 7),
            "é«˜é¢‘ (7-15Hz)": (7, 15),
            "è¶…é«˜é¢‘ (>15Hz)": (15, 20)
        }
        
        total_power = np.sum(power)
        band_powers = {}
        
        print(f"   â€¢ é¢‘å¸¦èƒ½é‡åˆ†å¸ƒ:")
        for band_name, (low, high) in bands.items():
            band_mask = (freqs >= low) & (freqs < high)
            band_power = np.sum(power[band_mask])
            band_ratio = (band_power / total_power) * 100 if total_power > 0 else 0
            band_powers[band_name] = band_ratio
            
            if band_ratio > 5:  # åªæ˜¾ç¤ºå æ¯”è¶…è¿‡5%çš„é¢‘å¸¦
                print(f"     - {band_name}: {band_ratio:.1f}%")
        
        # æ‰¾åˆ°ä¸»å¯¼é¢‘å¸¦
        dominant_band = max(band_powers, key=band_powers.get)
        print(f"   â€¢ ä¸»å¯¼é¢‘å¸¦: {dominant_band} ({band_powers[dominant_band]:.1f}%)")
        
        self.trajectory_analysis['ä¸»å¯¼é¢‘å¸¦'] = dominant_band
        self.trajectory_analysis['é¢‘å¸¦åˆ†å¸ƒ'] = band_powers
    
    def analyze_nystagmus_intensity_enhanced(self):
        """å¢å¼ºç‰ˆçœ¼éœ‡å¼ºåº¦åˆ†æ"""
        print(f"\nğŸ’ª å¢å¼ºç‰ˆçœ¼éœ‡å¼ºåº¦åˆ†æ:")
        
        actual_x = self.data['actualX'].values
        speed = self.data['Xè½´çœ¼åŠ¨é€Ÿåº¦'].values
        acceleration = self.data['Xè½´åŠ é€Ÿåº¦'].values
        
        # å¤šç»´åº¦å¼ºåº¦è¯„ä¼°
        # 1. ä½ç§»å¼ºåº¦
        displacement_range = np.max(actual_x) - np.min(actual_x)
        displacement_std = np.std(actual_x)
        displacement_rms = np.sqrt(np.mean((actual_x - np.mean(actual_x))**2))
        
        # 2. é€Ÿåº¦å¼ºåº¦
        speed_mean = np.mean(speed)
        speed_max = np.max(speed)
        speed_95th = np.percentile(speed, 95)
        
        # 3. åŠ é€Ÿåº¦å¼ºåº¦
        accel_mean = np.mean(acceleration)
        accel_max = np.max(acceleration)
        accel_95th = np.percentile(acceleration, 95)
        
        # 4. è¿åŠ¨å¤æ‚æ€§
        # ä½¿ç”¨è¿‘ä¼¼ç†µè¯„ä¼°ä¿¡å·å¤æ‚æ€§
        complexity = self.calculate_approximate_entropy(actual_x)
        
        # 5. è¿åŠ¨è¿ç»­æ€§
        # æ£€æµ‹è¿åŠ¨ä¸­æ–­ï¼ˆé€Ÿåº¦æ¥è¿‘é›¶çš„æ—¶é—´ï¼‰
        still_threshold = np.percentile(speed, 10)  # 10åˆ†ä½æ•°ä½œä¸ºé™æ­¢é˜ˆå€¼
        still_periods = speed < still_threshold
        continuity = 1 - (np.sum(still_periods) / len(speed))
        
        print(f"   â€¢ ä½ç§»å¼ºåº¦:")
        print(f"     - è¿åŠ¨èŒƒå›´: {displacement_range:.1f} åƒç´ ")
        print(f"     - æ ‡å‡†å·®: {displacement_std:.1f} åƒç´ ")
        print(f"     - RMS: {displacement_rms:.1f} åƒç´ ")
        
        print(f"   â€¢ é€Ÿåº¦å¼ºåº¦:")
        print(f"     - å¹³å‡é€Ÿåº¦: {speed_mean:.1f} åƒç´ /ç§’")
        print(f"     - æœ€å¤§é€Ÿåº¦: {speed_max:.1f} åƒç´ /ç§’")
        print(f"     - 95åˆ†ä½é€Ÿåº¦: {speed_95th:.1f} åƒç´ /ç§’")
        
        print(f"   â€¢ åŠ é€Ÿåº¦å¼ºåº¦:")
        print(f"     - å¹³å‡åŠ é€Ÿåº¦: {accel_mean:.1f} åƒç´ /ç§’Â²")
        print(f"     - æœ€å¤§åŠ é€Ÿåº¦: {accel_max:.1f} åƒç´ /ç§’Â²")
        print(f"     - 95åˆ†ä½åŠ é€Ÿåº¦: {accel_95th:.1f} åƒç´ /ç§’Â²")
        
        print(f"   â€¢ è¿åŠ¨ç‰¹æ€§:")
        print(f"     - ä¿¡å·å¤æ‚æ€§: {complexity:.3f}")
        print(f"     - è¿åŠ¨è¿ç»­æ€§: {continuity*100:.1f}%")
        
        # ç»¼åˆå¼ºåº¦è¯„çº§
        intensity_score = self.calculate_intensity_score(
            displacement_range, speed_mean, accel_mean, complexity, continuity
        )
        
        intensity_level = self.classify_intensity_level(intensity_score)
        print(f"   â€¢ ç»¼åˆå¼ºåº¦è¯„çº§: {intensity_level} (è¯„åˆ†: {intensity_score:.2f}/10)")
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_analysis.update({
            'ä½ç§»èŒƒå›´': displacement_range,
            'ä½ç§»æ ‡å‡†å·®': displacement_std,
            'ä½ç§»RMS': displacement_rms,
            'å¹³å‡é€Ÿåº¦': speed_mean,
            'æœ€å¤§é€Ÿåº¦': speed_max,
            'å¹³å‡åŠ é€Ÿåº¦': accel_mean,
            'æœ€å¤§åŠ é€Ÿåº¦': accel_max,
            'ä¿¡å·å¤æ‚æ€§': complexity,
            'è¿åŠ¨è¿ç»­æ€§': continuity,
            'å¼ºåº¦è¯„åˆ†': intensity_score,
            'å¼ºåº¦ç­‰çº§': intensity_level
        })
    
    def calculate_approximate_entropy(self, data, m=2, r=None):
        """è®¡ç®—è¿‘ä¼¼ç†µï¼Œè¯„ä¼°ä¿¡å·çš„å¤æ‚æ€§å’Œè§„å¾‹æ€§"""
        N = len(data)
        if r is None:
            r = 0.2 * np.std(data)
        
        def _maxdist(xi, xj, N, m):
            return max([abs(ua - va) for ua, va in zip(xi, xj)])
        
        def _phi(m):
            patterns = []
            for i in range(N - m + 1):
                patterns.append(data[i:i + m])
            
            C = []
            for i in range(N - m + 1):
                template_i = patterns[i]
                matches = 0
                for j in range(N - m + 1):
                    if _maxdist(template_i, patterns[j], N, m) <= r:
                        matches += 1
                C.append(matches / (N - m + 1))
            
            phi = np.mean([np.log(c) for c in C if c > 0])
            return phi
        
        try:
            return _phi(m) - _phi(m + 1)
        except:
            return 0.0
    
    def calculate_intensity_score(self, disp_range, speed_mean, accel_mean, complexity, continuity):
        """è®¡ç®—ç»¼åˆå¼ºåº¦è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰"""
        # å½’ä¸€åŒ–å„ä¸ªæŒ‡æ ‡åˆ°0-1èŒƒå›´
        disp_score = min(1, disp_range / 100)  # 100åƒç´ ä¸ºæ»¡åˆ†
        speed_score = min(1, speed_mean / 500)  # 500åƒç´ /ç§’ä¸ºæ»¡åˆ†
        accel_score = min(1, accel_mean / 2000)  # 2000åƒç´ /ç§’Â²ä¸ºæ»¡åˆ†
        complexity_score = min(1, complexity / 1.0)  # 1.0ä¸ºæ»¡åˆ†
        continuity_score = continuity  # å·²ç»æ˜¯0-1èŒƒå›´
        
        # åŠ æƒå¹³å‡
        weights = [0.25, 0.25, 0.2, 0.15, 0.15]  # ä½ç§»ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦ã€å¤æ‚æ€§ã€è¿ç»­æ€§
        scores = [disp_score, speed_score, accel_score, complexity_score, continuity_score]
        
        total_score = sum(w * s for w, s in zip(weights, scores)) * 10
        return min(10, max(0, total_score))
    
    def classify_intensity_level(self, score):
        """æ ¹æ®è¯„åˆ†åˆ†ç±»å¼ºåº¦ç­‰çº§"""
        if score >= 8:
            return "æé‡åº¦çœ¼éœ‡"
        elif score >= 6:
            return "é‡åº¦çœ¼éœ‡"
        elif score >= 4:
            return "ä¸­åº¦çœ¼éœ‡"
        elif score >= 2:
            return "è½»åº¦çœ¼éœ‡"
        else:
            return "å¾®å¼±çœ¼éœ‡"
    
    def analyze_nystagmus_waveform(self):
        """åˆ†æçœ¼éœ‡æ³¢å½¢ç‰¹å¾"""
        print(f"\nğŸŒŠ çœ¼éœ‡æ³¢å½¢ç‰¹å¾åˆ†æ:")
        
        smooth_x = self.data['å¹³æ»‘_X'].values
        vx = self.data['é€Ÿåº¦_X'].values
        
        # æ³¢å½¢å¯¹ç§°æ€§åˆ†æ
        symmetry = self.calculate_waveform_symmetry(smooth_x)
        
        # æ³¢å½¢å¹³æ»‘åº¦åˆ†æ
        smoothness = self.calculate_waveform_smoothness(smooth_x)
        
        # å³°å€¼åˆ†æ
        peaks_positive, _ = find_peaks(smooth_x, distance=self.fps//10)  # æœ€å°‘é—´éš”0.1ç§’
        peaks_negative, _ = find_peaks(-smooth_x, distance=self.fps//10)
        
        peak_amplitude_pos = np.mean(smooth_x[peaks_positive]) if len(peaks_positive) > 0 else 0
        peak_amplitude_neg = np.mean(-smooth_x[peaks_negative]) if len(peaks_negative) > 0 else 0
        
        # æ³¢å½¢å‘¨æœŸæ€§åˆ†æ
        periodicity = self.calculate_waveform_periodicity(smooth_x)
        
        print(f"   â€¢ æ³¢å½¢å¯¹ç§°æ€§: {symmetry:.3f} (1ä¸ºå®Œå…¨å¯¹ç§°)")
        print(f"   â€¢ æ³¢å½¢å¹³æ»‘åº¦: {smoothness:.3f}")
        print(f"   â€¢ æ­£å‘å³°å€¼: {len(peaks_positive)}ä¸ª (å¹³å‡å¹…åº¦: {peak_amplitude_pos:.1f}px)")
        print(f"   â€¢ è´Ÿå‘å³°å€¼: {len(peaks_negative)}ä¸ª (å¹³å‡å¹…åº¦: {peak_amplitude_neg:.1f}px)")
        print(f"   â€¢ æ³¢å½¢å‘¨æœŸæ€§: {periodicity:.3f}")
        
        # æ³¢å½¢åˆ†ç±»
        waveform_type = self.classify_waveform_type(symmetry, smoothness, periodicity)
        print(f"   â€¢ æ³¢å½¢ç±»å‹: {waveform_type}")
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_analysis.update({
            'æ³¢å½¢å¯¹ç§°æ€§': symmetry,
            'æ³¢å½¢å¹³æ»‘åº¦': smoothness,
            'æ­£å‘å³°å€¼æ•°': len(peaks_positive),
            'è´Ÿå‘å³°å€¼æ•°': len(peaks_negative),
            'æ³¢å½¢å‘¨æœŸæ€§': periodicity,
            'æ³¢å½¢ç±»å‹': waveform_type
        })
    
    def calculate_waveform_symmetry(self, signal):
        """è®¡ç®—æ³¢å½¢å¯¹ç§°æ€§"""
        # è®¡ç®—ä¿¡å·çš„ååº¦ï¼Œè¶Šæ¥è¿‘0è¶Šå¯¹ç§°
        from scipy.stats import skew
        skew_value = abs(skew(signal))
        symmetry = 1 / (1 + skew_value)  # è½¬æ¢ä¸º0-1èŒƒå›´ï¼Œ1ä¸ºå®Œå…¨å¯¹ç§°
        return symmetry
    
    def calculate_waveform_smoothness(self, signal):
        """è®¡ç®—æ³¢å½¢å¹³æ»‘åº¦"""
        # ä½¿ç”¨äºŒé˜¶å·®åˆ†è¯„ä¼°å¹³æ»‘åº¦
        if len(signal) < 3:
            return 0
        
        second_diff = np.diff(signal, n=2)
        roughness = np.var(second_diff)
        smoothness = 1 / (1 + roughness)  # è½¬æ¢ä¸ºå¹³æ»‘åº¦æŒ‡æ ‡
        return smoothness
    
    def calculate_waveform_periodicity(self, signal):
        """è®¡ç®—æ³¢å½¢å‘¨æœŸæ€§"""
        # ä½¿ç”¨è‡ªç›¸å…³å‡½æ•°è¯„ä¼°å‘¨æœŸæ€§
        if len(signal) < 10:
            return 0
        
        # è®¡ç®—å½’ä¸€åŒ–è‡ªç›¸å…³
        correlation = np.correlate(signal, signal, mode='full')
        correlation = correlation[correlation.size // 2:]
        correlation = correlation / correlation[0]  # å½’ä¸€åŒ–
        
        # å¯»æ‰¾ç¬¬ä¸€ä¸ªæ˜¾è‘—çš„æ­£ç›¸å…³å³°å€¼ï¼ˆæ’é™¤lag=0ï¼‰
        if len(correlation) > self.fps:  # è‡³å°‘1ç§’çš„æ•°æ®
            peaks, _ = find_peaks(correlation[1:min(len(correlation), self.fps*3)], 
                                height=0.3, distance=self.fps//10)
            
            if len(peaks) > 0:
                # è¿”å›æœ€å¼ºçš„å‘¨æœŸæ€§ç›¸å…³å€¼
                return correlation[peaks[0] + 1]
            else:
                return 0
        else:
            return 0
    
    def classify_waveform_type(self, symmetry, smoothness, periodicity):
        """åˆ†ç±»æ³¢å½¢ç±»å‹"""
        if periodicity > 0.6 and smoothness > 0.7:
            if symmetry > 0.8:
                return "è§„å¾‹æ­£å¼¦æ³¢å‹"
            else:
                return "è§„å¾‹éå¯¹ç§°æ³¢å‹"
        elif periodicity > 0.4:
            if smoothness > 0.5:
                return "åŠè§„å¾‹å¹³æ»‘æ³¢å‹"
            else:
                return "åŠè§„å¾‹é”¯é½¿æ³¢å‹"
        elif smoothness > 0.7:
            return "ä¸è§„åˆ™å¹³æ»‘æ³¢å‹"
        else:
            return "ä¸è§„åˆ™å™ªå£°æ³¢å‹"
    
    def analyze_nystagmus_directionality(self):
        """åˆ†æçœ¼éœ‡æ–¹å‘æ€§ç‰¹å¾"""
        print(f"\nğŸ§­ çœ¼éœ‡æ–¹å‘æ€§åˆ†æ:")
        
        vx = self.data['é€Ÿåº¦_X'].values
        actual_x = self.data['actualX'].values
        
        # æ–¹å‘åå¥½åˆ†æ
        positive_velocity_time = np.sum(vx > 0) / len(vx)
        negative_velocity_time = np.sum(vx < 0) / len(vx)
        stationary_time = np.sum(np.abs(vx) < 10) / len(vx)  # é€Ÿåº¦<10px/sè§†ä¸ºé™æ­¢
        
        # æ–¹å‘æŒç»­æ€§åˆ†æ
        direction_persistence = self.calculate_direction_persistence(vx)
        
        # è¿åŠ¨èŒƒå›´åˆ†æ
        center_position = np.mean(actual_x)
        rightward_extent = np.max(actual_x) - center_position
        leftward_extent = center_position - np.min(actual_x)
        
        # æ–¹å‘æ€§å¼ºåº¦
        directional_bias = abs(positive_velocity_time - negative_velocity_time)
        
        print(f"   â€¢ æ–¹å‘æ—¶é—´åˆ†å¸ƒ:")
        print(f"     - å³å‘è¿åŠ¨: {positive_velocity_time*100:.1f}%")
        print(f"     - å·¦å‘è¿åŠ¨: {negative_velocity_time*100:.1f}%")
        print(f"     - ç›¸å¯¹é™æ­¢: {stationary_time*100:.1f}%")
        
        print(f"   â€¢ è¿åŠ¨èŒƒå›´:")
        print(f"     - å³å‘æœ€å¤§ä½ç§»: {rightward_extent:.1f} åƒç´ ")
        print(f"     - å·¦å‘æœ€å¤§ä½ç§»: {leftward_extent:.1f} åƒç´ ")
        print(f"     - ä¸­å¿ƒä½ç½®: {center_position:.1f} åƒç´ ")
        
        print(f"   â€¢ æ–¹å‘ç‰¹æ€§:")
        print(f"     - æ–¹å‘æŒç»­æ€§: {direction_persistence:.3f}")
        print(f"     - æ–¹å‘åå‘æ€§: {directional_bias:.3f}")
        
        # æ–¹å‘æ¨¡å¼åˆ†ç±»
        direction_pattern = self.classify_direction_pattern(
            positive_velocity_time, negative_velocity_time, directional_bias, direction_persistence
        )
        print(f"   â€¢ æ–¹å‘æ¨¡å¼: {direction_pattern}")
        
        # å­˜å‚¨ç»“æœ
        self.trajectory_analysis.update({
            'å³å‘è¿åŠ¨æ¯”ä¾‹': positive_velocity_time,
            'å·¦å‘è¿åŠ¨æ¯”ä¾‹': negative_velocity_time,
            'é™æ­¢æ¯”ä¾‹': stationary_time,
            'å³å‘æœ€å¤§ä½ç§»': rightward_extent,
            'å·¦å‘æœ€å¤§ä½ç§»': leftward_extent,
            'æ–¹å‘æŒç»­æ€§': direction_persistence,
            'æ–¹å‘åå‘æ€§': directional_bias,
            'æ–¹å‘æ¨¡å¼': direction_pattern
        })
    
    def calculate_direction_persistence(self, velocity):
        """è®¡ç®—æ–¹å‘æŒç»­æ€§"""
        # è®¡ç®—è¿ç»­åŒæ–¹å‘è¿åŠ¨çš„å¹³å‡é•¿åº¦
        direction_changes = np.diff(np.sign(velocity))
        change_points = np.where(direction_changes != 0)[0]
        
        if len(change_points) < 2:
            return 1.0  # å¦‚æœæ²¡æœ‰æ–¹å‘å˜åŒ–ï¼ŒæŒç»­æ€§ä¸º1
        
        # è®¡ç®—å„æ®µçš„é•¿åº¦
        segment_lengths = np.diff(np.concatenate([[0], change_points, [len(velocity)-1]]))
        
        # æ–¹å‘æŒç»­æ€§ = å¹³å‡æ®µé•¿åº¦ / æ€»é•¿åº¦
        persistence = np.mean(segment_lengths) / len(velocity)
        return min(1.0, persistence)
    
    def classify_direction_pattern(self, pos_ratio, neg_ratio, bias, persistence):
        """åˆ†ç±»æ–¹å‘æ¨¡å¼"""
        if bias > 0.3:  # æ˜æ˜¾çš„æ–¹å‘åå¥½
            if pos_ratio > neg_ratio:
                return "å³å‘åå¥½å‹"
            else:
                return "å·¦å‘åå¥½å‹"
        elif persistence > 0.7:
            return "åŒå‘å¯¹ç§°æŒç»­å‹"
        elif persistence > 0.3:
            return "åŒå‘å¯¹ç§°é—´æ­‡å‹"
        else:
            return "å¿«é€Ÿå˜å‘å‹"

    def print_comprehensive_trajectory_report(self):
        """æ‰“å°å…¨é¢çš„è½¨è¿¹åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*100)
        print("ğŸ¯ Xè½´çœ¼éœ‡è½¨è¿¹å…¨é¢åˆ†ææŠ¥å‘Š")
        print("="*100)
        
        if not self.trajectory_analysis:
            print("âŒ è½¨è¿¹åˆ†ææ•°æ®ä¸å¯ç”¨")
            return
        
        # çœ¼éœ‡åŸºæœ¬åˆ†ç±»
        print(f"\nğŸ“Š çœ¼éœ‡åŸºæœ¬ç‰¹å¾:")
        print(f"   â€¢ ç±»å‹åˆ†ç±»: {', '.join(self.trajectory_analysis.get('çœ¼éœ‡ç±»å‹', ['æœªçŸ¥']))}")
        print(f"   â€¢ è¿åŠ¨æ¨¡å¼: {self.trajectory_analysis.get('çœ¼éœ‡æ¨¡å¼', 'æœªçŸ¥')}")
        print(f"   â€¢ æ¨¡å¼æè¿°: {self.trajectory_analysis.get('æ¨¡å¼æè¿°', 'æ— æè¿°')}")
        print(f"   â€¢ å¼ºåº¦ç­‰çº§: {self.trajectory_analysis.get('å¼ºåº¦ç­‰çº§', 'æœªçŸ¥')} (è¯„åˆ†: {self.trajectory_analysis.get('å¼ºåº¦è¯„åˆ†', 0):.1f}/10)")
        
        # é¢‘ç‡ç‰¹å¾
        print(f"\nğŸ“¡ é¢‘ç‡ç‰¹å¾:")
        if self.trajectory_analysis.get('ä¸»é¢‘ç‡', 0) > 0:
            print(f"   â€¢ ä¸»é¢‘ç‡: {self.trajectory_analysis['ä¸»é¢‘ç‡']:.3f} Hz")
            print(f"   â€¢ é¢‘ç‡åˆ†ç±»: {self.trajectory_analysis.get('é¢‘ç‡åˆ†ç±»', 'æœªåˆ†ç±»')}")
            print(f"   â€¢ é¢‘ç‡ç¨³å®šæ€§: {self.trajectory_analysis.get('é¢‘ç‡ç¨³å®šæ€§', 0):.3f}")
            print(f"   â€¢ ä¸»å¯¼é¢‘å¸¦: {self.trajectory_analysis.get('ä¸»å¯¼é¢‘å¸¦', 'æœªçŸ¥')}")
            print(f"   â€¢ è°æ³¢æ•°é‡: {self.trajectory_analysis.get('è°æ³¢æ•°é‡', 0)}ä¸ª")
        else:
            print(f"   â€¢ ä¸»é¢‘ç‡: æ— æ˜æ˜¾é¢‘ç‡ç‰¹å¾")
        
        # è¿åŠ¨å¼ºåº¦
        print(f"\nğŸ’ª è¿åŠ¨å¼ºåº¦:")
        print(f"   â€¢ ä½ç§»èŒƒå›´: {self.trajectory_analysis.get('ä½ç§»èŒƒå›´', 0):.1f} åƒç´ ")
        print(f"   â€¢ ä½ç§»RMS: {self.trajectory_analysis.get('ä½ç§»RMS', 0):.1f} åƒç´ ")
        print(f"   â€¢ å¹³å‡é€Ÿåº¦: {self.trajectory_analysis.get('å¹³å‡é€Ÿåº¦', 0):.1f} åƒç´ /ç§’")
        print(f"   â€¢ æœ€å¤§é€Ÿåº¦: {self.trajectory_analysis.get('æœ€å¤§é€Ÿåº¦', 0):.1f} åƒç´ /ç§’")
        print(f"   â€¢ å¹³å‡åŠ é€Ÿåº¦: {self.trajectory_analysis.get('å¹³å‡åŠ é€Ÿåº¦', 0):.1f} åƒç´ /ç§’Â²")
        print(f"   â€¢ ä¿¡å·å¤æ‚æ€§: {self.trajectory_analysis.get('ä¿¡å·å¤æ‚æ€§', 0):.3f}")
        print(f"   â€¢ è¿åŠ¨è¿ç»­æ€§: {self.trajectory_analysis.get('è¿åŠ¨è¿ç»­æ€§', 0)*100:.1f}%")
        
        # æ³¢å½¢ç‰¹å¾
        print(f"\nğŸŒŠ æ³¢å½¢ç‰¹å¾:")
        print(f"   â€¢ æ³¢å½¢ç±»å‹: {self.trajectory_analysis.get('æ³¢å½¢ç±»å‹', 'æœªçŸ¥')}")
        print(f"   â€¢ æ³¢å½¢å¯¹ç§°æ€§: {self.trajectory_analysis.get('æ³¢å½¢å¯¹ç§°æ€§', 0):.3f}")
        print(f"   â€¢ æ³¢å½¢å¹³æ»‘åº¦: {self.trajectory_analysis.get('æ³¢å½¢å¹³æ»‘åº¦', 0):.3f}")
        print(f"   â€¢ æ³¢å½¢å‘¨æœŸæ€§: {self.trajectory_analysis.get('æ³¢å½¢å‘¨æœŸæ€§', 0):.3f}")
        print(f"   â€¢ æ­£å‘å³°å€¼: {self.trajectory_analysis.get('æ­£å‘å³°å€¼æ•°', 0)}ä¸ª")
        print(f"   â€¢ è´Ÿå‘å³°å€¼: {self.trajectory_analysis.get('è´Ÿå‘å³°å€¼æ•°', 0)}ä¸ª")
        
        # æ–¹å‘æ€§ç‰¹å¾
        print(f"\nğŸ§­ æ–¹å‘æ€§ç‰¹å¾:")
        print(f"   â€¢ æ–¹å‘æ¨¡å¼: {self.trajectory_analysis.get('æ–¹å‘æ¨¡å¼', 'æœªçŸ¥')}")
        print(f"   â€¢ å³å‘è¿åŠ¨: {self.trajectory_analysis.get('å³å‘è¿åŠ¨æ¯”ä¾‹', 0)*100:.1f}%")
        print(f"   â€¢ å·¦å‘è¿åŠ¨: {self.trajectory_analysis.get('å·¦å‘è¿åŠ¨æ¯”ä¾‹', 0)*100:.1f}%")
        print(f"   â€¢ ç›¸å¯¹é™æ­¢: {self.trajectory_analysis.get('é™æ­¢æ¯”ä¾‹', 0)*100:.1f}%")
        print(f"   â€¢ æ–¹å‘æŒç»­æ€§: {self.trajectory_analysis.get('æ–¹å‘æŒç»­æ€§', 0):.3f}")
        print(f"   â€¢ æ–¹å‘åå‘æ€§: {self.trajectory_analysis.get('æ–¹å‘åå‘æ€§', 0):.3f}")
        print(f"   â€¢ å³å‘æœ€å¤§ä½ç§»: {self.trajectory_analysis.get('å³å‘æœ€å¤§ä½ç§»', 0):.1f} åƒç´ ")
        print(f"   â€¢ å·¦å‘æœ€å¤§ä½ç§»: {self.trajectory_analysis.get('å·¦å‘æœ€å¤§ä½ç§»', 0):.1f} åƒç´ ")
        
        # ä¸´åºŠæ„ä¹‰è¯„ä¼°
        print(f"\nğŸ¥ ä¸´åºŠæ„ä¹‰è¯„ä¼°:")
        self.assess_clinical_significance()
        
    def assess_clinical_significance(self):
        """è¯„ä¼°çœ¼éœ‡çš„ä¸´åºŠæ„ä¹‰"""
        # åŸºäºåˆ†æç»“æœè¯„ä¼°ä¸´åºŠæ„ä¹‰
        intensity_score = self.trajectory_analysis.get('å¼ºåº¦è¯„åˆ†', 0)
        main_freq = self.trajectory_analysis.get('ä¸»é¢‘ç‡', 0)
        pattern = self.trajectory_analysis.get('çœ¼éœ‡æ¨¡å¼', '')
        symmetry = self.trajectory_analysis.get('æ³¢å½¢å¯¹ç§°æ€§', 0)
        
        clinical_notes = []
        
        # å¼ºåº¦è¯„ä¼°
        if intensity_score >= 7:
            clinical_notes.append("âš ï¸ é«˜å¼ºåº¦çœ¼éœ‡ï¼Œå¯èƒ½å½±å“è§†è§‰åŠŸèƒ½")
        elif intensity_score >= 4:
            clinical_notes.append("âš¡ ä¸­ç­‰å¼ºåº¦çœ¼éœ‡ï¼Œéœ€è¦å…³æ³¨")
        else:
            clinical_notes.append("âœ… ä½å¼ºåº¦çœ¼éœ‡ï¼Œç›¸å¯¹è½»å¾®")
        
        # é¢‘ç‡è¯„ä¼°
        if 1 <= main_freq <= 5:
            clinical_notes.append("ğŸ“¡ é¢‘ç‡åœ¨æ­£å¸¸çœ¼éœ‡èŒƒå›´å†…")
        elif main_freq > 8:
            clinical_notes.append("âš ï¸ é«˜é¢‘çœ¼éœ‡ï¼Œå¯èƒ½æç¤ºä¸­æ¢æ€§ç—…å˜")
        elif main_freq > 0 and main_freq < 1:
            clinical_notes.append("ğŸ”„ ä½é¢‘çœ¼éœ‡ï¼Œå¯èƒ½æç¤ºå‰åº­åŠŸèƒ½å¼‚å¸¸")
        
        # æ¨¡å¼è¯„ä¼°
        if "å†²åŠ¨æ€§" in pattern:
            clinical_notes.append("ğŸ¯ å†²åŠ¨æ€§çœ¼éœ‡æ¨¡å¼ï¼Œæç¤ºå‰åº­ç³»ç»Ÿå¼‚å¸¸")
        elif "æ‘†åŠ¨æ€§" in pattern:
            clinical_notes.append("âš–ï¸ æ‘†åŠ¨æ€§çœ¼éœ‡æ¨¡å¼ï¼Œå¯èƒ½ä¸ºå…ˆå¤©æ€§æˆ–è·å¾—æ€§")
        
        # å¯¹ç§°æ€§è¯„ä¼°
        if symmetry < 0.5:
            clinical_notes.append("âš ï¸ æ³¢å½¢ä¸å¯¹ç§°ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°")
        
        for note in clinical_notes:
            print(f"   {note}")
        
        if not clinical_notes:
            print("   ğŸ“Š çœ¼éœ‡ç‰¹å¾åœ¨å¯æ¥å—èŒƒå›´å†…")

    # ======================
    # åŸæœ‰çš„UKFé¢„æµ‹åˆ†æåŠŸèƒ½ä¿æŒä¸å˜
    # ======================
    
    def calculate_errors(self):
        """è®¡ç®—Xè½´è¯¯å·®æŒ‡æ ‡ï¼ˆä½¿ç”¨å·²æœ‰çš„è¯¯å·®æ•°æ®ï¼‰"""
        if self.data is None:
            print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        # è®¡ç®—è¯¯å·®ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
        if 'predictionErrorX' not in self.data.columns:
            self.data['predictionErrorX'] = self.data['actualX'] - self.data['predictedX']
        
        # ä½¿ç”¨æ–°çš„åˆ—å
        self.data['è¯¯å·®_X'] = self.data['predictionErrorX']
        self.data['ç»å¯¹è¯¯å·®_X'] = np.abs(self.data['è¯¯å·®_X'])
        
        # å¦‚æœæœ‰errorMagnitudeï¼Œç›´æ¥ä½¿ç”¨
        if 'errorMagnitude' in self.data.columns:
            self.data['æ€»è¯¯å·®'] = self.data['errorMagnitude']
        
        # è®¡ç®—ç›¸å¯¹è¯¯å·®ï¼ˆè€ƒè™‘åˆ°å±å¹•å®½åº¦ï¼‰
        screen_width = 1920  # å‡è®¾1920åƒç´ å®½åº¦
        self.data['ç›¸å¯¹è¯¯å·®_X'] = (self.data['ç»å¯¹è¯¯å·®_X'] / screen_width) * 100
        
        # è®¡ç®—è¯¯å·®çš„ç§»åŠ¨å¹³å‡ï¼ˆç”¨äºè¶‹åŠ¿åˆ†æï¼‰
        window_size = min(10, len(self.data) // 20)
        if window_size > 1:
            self.data['è¯¯å·®_ç§»åŠ¨å¹³å‡'] = self.data['è¯¯å·®_X'].rolling(window=window_size, center=True).mean()
            self.data['ç»å¯¹è¯¯å·®_ç§»åŠ¨å¹³å‡'] = self.data['ç»å¯¹è¯¯å·®_X'].rolling(window=window_size, center=True).mean()
        
        print("âœ… Xè½´è¯¯å·®è®¡ç®—å®Œæˆ")
    
    def calculate_accuracy_metrics(self):
        """è®¡ç®—Xè½´å‡†ç¡®æ€§æŒ‡æ ‡ï¼ˆä¿®æ­£NRMSEè®¡ç®—ï¼‰"""
        if self.data is None:
            return
        
        metrics = {}
        
        # åŸºç¡€è¯¯å·®æŒ‡æ ‡
        metrics['å¹³å‡ç»å¯¹è¯¯å·®'] = self.data['ç»å¯¹è¯¯å·®_X'].mean()
        metrics['ä¸­ä½æ•°ç»å¯¹è¯¯å·®'] = self.data['ç»å¯¹è¯¯å·®_X'].median()
        metrics['æœ€å¤§ç»å¯¹è¯¯å·®'] = self.data['ç»å¯¹è¯¯å·®_X'].max()
        metrics['æœ€å°ç»å¯¹è¯¯å·®'] = self.data['ç»å¯¹è¯¯å·®_X'].min()
        metrics['è¯¯å·®æ ‡å‡†å·®'] = self.data['ç»å¯¹è¯¯å·®_X'].std()
        
        # å¦‚æœæœ‰æ€»è¯¯å·®ï¼Œä¹Ÿè®¡ç®—æ€»è¯¯å·®çš„ç»Ÿè®¡
        if 'errorMagnitude' in self.data.columns:
            metrics['å¹³å‡æ€»è¯¯å·®'] = self.data['errorMagnitude'].mean()
            metrics['æœ€å¤§æ€»è¯¯å·®'] = self.data['errorMagnitude'].max()
        
        # ç³»ç»Ÿæ€§åå·®
        metrics['Xè½´ç³»ç»Ÿåå·®'] = self.data['è¯¯å·®_X'].mean()
        
        # ç›¸å…³æ€§å’Œå†³å®šç³»æ•°
        metrics['Xè½´ç›¸å…³æ€§'] = self.data['actualX'].corr(self.data['predictedX'])
        metrics['Xè½´RÂ²'] = r2_score(self.data['actualX'], self.data['predictedX'])
        
        # MSEå’ŒRMSE
        metrics['Xè½´MSE'] = mean_squared_error(self.data['actualX'], self.data['predictedX'])
        metrics['Xè½´RMSE'] = np.sqrt(metrics['Xè½´MSE'])
        metrics['Xè½´MAE'] = mean_absolute_error(self.data['actualX'], self.data['predictedX'])
        
        # ä¿®æ­£çš„NRMSEè®¡ç®—
        Yref = self.data['actualX'].values  # çœŸå®å€¼
        Y = self.data['predictedX'].values   # é¢„æµ‹å€¼
        Yref_mean = np.mean(Yref)           # çœŸå®å€¼çš„å‡å€¼
        
        # è®¡ç®—åˆ†å­ï¼š||Yref - Y||ï¼ˆé¢„æµ‹è¯¯å·®çš„èŒƒæ•°ï¼‰
        numerator = np.linalg.norm(Yref - Y)
        
        # è®¡ç®—åˆ†æ¯ï¼š||Yref - mean(Yref)||ï¼ˆçœŸå®å€¼ä¸å…¶å‡å€¼çš„èŒƒæ•°ï¼‰
        denominator = np.linalg.norm(Yref - Yref_mean)
        
        # è®¡ç®—ä¿®æ­£çš„NRMSE
        if denominator > 0:
            metrics['Xè½´NRMSE_ä¿®æ­£'] = 1 - (numerator / denominator)
        else:
            metrics['Xè½´NRMSE_ä¿®æ­£'] = 0
        
        # ä¸ºäº†å¯¹æ¯”ï¼Œä¿ç•™åŸæ¥çš„è®¡ç®—æ–¹æ³•
        data_range = self.data['actualX'].max() - self.data['actualX'].min()
        if data_range > 0:
            metrics['Xè½´NRMSE_åŸå§‹'] = metrics['Xè½´RMSE'] / data_range
        else:
            metrics['Xè½´NRMSE_åŸå§‹'] = 0
        
        # ç²¾åº¦ç­‰çº§åˆ†å¸ƒ
        thresholds = [1, 2, 3, 5, 10, 15, 20, 30, 50, 100]
        for t in thresholds:
            metrics[f'{t}åƒç´ å†…'] = (self.data['ç»å¯¹è¯¯å·®_X'] <= t).sum() / len(self.data) * 100
        
        # è®¡ç®—è§†è§’è¯¯å·®ï¼ˆå‡è®¾è§‚çœ‹è·ç¦»60cmï¼Œå±å¹•PPI=96ï¼‰
        viewing_distance_cm = 60
        pixels_per_cm = 96 / 2.54  # 96 DPIè½¬æ¢
        visual_angle = np.degrees(2 * np.arctan(
            (self.data['ç»å¯¹è¯¯å·®_X'] / pixels_per_cm) / (2 * viewing_distance_cm)
        ))
        metrics['å¹³å‡è§†è§’è¯¯å·®'] = visual_angle.mean()
        metrics['æœ€å°è§†è§’è¯¯å·®'] = visual_angle.min()
        metrics['æœ€å¤§è§†è§’è¯¯å·®'] = visual_angle.max()
        
        # è®¡ç®—UKFé¢„æµ‹ç¨³å®šæ€§æŒ‡æ ‡
        if len(self.data) > 1:
            pred_change = np.diff(self.data['predictedX'])
            metrics['UKFé¢„æµ‹å¹³æ»‘åº¦'] = np.abs(pred_change).mean()
            metrics['UKFé¢„æµ‹æŠ–åŠ¨åº¦'] = np.abs(pred_change).std()
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        confidence_95 = 1.96 * metrics['è¯¯å·®æ ‡å‡†å·®'] / np.sqrt(len(self.data))
        metrics['95%ç½®ä¿¡åŒºé—´'] = f"Â±{confidence_95:.2f}"
        
        self.metrics = metrics
        return metrics
    
    def analyze_nystagmus_reduction(self):
        """ä»¥ç¬¬ä¸€å¸§ä¸ºä¸­å¿ƒåˆ†æçœ¼éœ‡å‡ç¼“æ•ˆæœï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        if len(self.data) < 2:
            print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‡ç¼“åˆ†æ")
            return
            
        print("\n" + "="*80)
        print("ğŸ¯ çœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æï¼ˆä»¥ç¬¬ä¸€å¸§ä¸ºå‚è€ƒä¸­å¿ƒï¼Œä¿®æ­£ç‰ˆï¼‰")
        print("="*80)
        
        # 1. è®¾ç½®ç¬¬ä¸€å¸§ä¸ºå‚è€ƒä¸­å¿ƒç‚¹
        first_frame = self.data.iloc[0]
        self.reference_point = {
            'frameId': first_frame['frameId'],
            'actualX': first_frame['actualX'],
            'predictedX': first_frame['predictedX']
        }
        
        print(f"\nğŸ“ å‚è€ƒä¸­å¿ƒç‚¹ï¼ˆç¬¬ä¸€å¸§ï¼‰:")
        print(f"   å¸§ID: {self.reference_point['frameId']}")
        print(f"   çœŸå®Xåæ ‡: {self.reference_point['actualX']:.2f}")
        print(f"   é¢„æµ‹Xåæ ‡: {self.reference_point['predictedX']:.2f}")
        
        # 2. è®¡ç®—æ¯å¸§ç›¸å¯¹äºç¬¬ä¸€å¸§çš„ä½ç§»
        self.data['çœŸå®ä½ç§»_X'] = self.data['actualX'] - self.reference_point['actualX']
        self.data['é¢„æµ‹ä½ç§»_X'] = self.data['predictedX'] - self.reference_point['actualX']  # éƒ½ä»¥çœŸå®å€¼ä½œä¸ºå‚è€ƒ
        self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'] = np.abs(self.data['çœŸå®ä½ç§»_X'])
        self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'] = np.abs(self.data['é¢„æµ‹ä½ç§»_X'])
        
        # 3. ä¿®æ­£çš„å‡ç¼“åŒºåŸŸè®¡ç®—
        # å…¬å…±åŒºåŸŸï¼ˆå‡ç¼“åŒºåŸŸï¼‰= çœŸå®ä½ç§»å’Œé¢„æµ‹ä½ç§»çš„é‡å éƒ¨åˆ†
        self.data['å…¬å…±åŒºåŸŸ_å‡ç¼“'] = np.minimum(self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'], self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'])
        
        # æ®‹ä½™çœ¼éœ‡ = é¢„æµ‹æ— æ³•è¦†ç›–çš„çœŸå®çœ¼éœ‡éƒ¨åˆ†
        self.data['æ®‹ä½™çœ¼éœ‡'] = np.maximum(0, self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'] - self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'])
        
        # å¼‚å¸¸å¢å¼º = é¢„æµ‹è¶…å‡ºçœŸå®çœ¼éœ‡çš„éƒ¨åˆ†ï¼ˆè¿™æ˜¯ä¸å¥½çš„ï¼‰
        self.data['å¼‚å¸¸å¢å¼º'] = np.maximum(0, self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'] - self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'])
        
        # æ€»å‡ç¼“é‡ = åŸæœ¬çœ¼éœ‡ - æ®‹ä½™çœ¼éœ‡
        self.data['æ€»å‡ç¼“é‡'] = self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'] - self.data['æ®‹ä½™çœ¼éœ‡']
        
        # å‡ç¼“æ•ˆç‡ = å‡ç¼“é‡ / åŸæœ¬çœ¼éœ‡
        self.data['å‡ç¼“æ•ˆç‡'] = np.where(
            self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'] > 0,
            (self.data['æ€»å‡ç¼“é‡'] / self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼']) * 100,
            0
        )
        
        # 4. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        self.reduction_analysis = {}
        self.reduction_analysis['å¹³å‡çœŸå®ä½ç§»'] = self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'].mean()
        self.reduction_analysis['å¹³å‡é¢„æµ‹ä½ç§»'] = self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'].mean()
        self.reduction_analysis['å¹³å‡å…¬å…±åŒºåŸŸ'] = self.data['å…¬å…±åŒºåŸŸ_å‡ç¼“'].mean()
        self.reduction_analysis['å¹³å‡æ®‹ä½™çœ¼éœ‡'] = self.data['æ®‹ä½™çœ¼éœ‡'].mean()
        self.reduction_analysis['å¹³å‡å¼‚å¸¸å¢å¼º'] = self.data['å¼‚å¸¸å¢å¼º'].mean()
        self.reduction_analysis['å¹³å‡å‡ç¼“é‡'] = self.data['æ€»å‡ç¼“é‡'].mean()
        self.reduction_analysis['å¹³å‡å‡ç¼“æ•ˆç‡'] = self.data['å‡ç¼“æ•ˆç‡'].mean()
        
        # æœ€å¤§å€¼ç»Ÿè®¡
        self.reduction_analysis['æœ€å¤§çœŸå®ä½ç§»'] = self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'].max()
        self.reduction_analysis['æœ€å¤§é¢„æµ‹ä½ç§»'] = self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'].max()
        self.reduction_analysis['æœ€å¤§æ®‹ä½™çœ¼éœ‡'] = self.data['æ®‹ä½™çœ¼éœ‡'].max()
        self.reduction_analysis['æœ€å¤§å¼‚å¸¸å¢å¼º'] = self.data['å¼‚å¸¸å¢å¼º'].max()
        
        # æ”¹å–„å’Œæ¶åŒ–ç»Ÿè®¡
        improved_frames = (self.data['æ®‹ä½™çœ¼éœ‡'] < self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼']).sum()
        worsened_frames = (self.data['å¼‚å¸¸å¢å¼º'] > 0).sum()
        self.reduction_analysis['æ”¹å–„å¸§æ•°'] = improved_frames
        self.reduction_analysis['æ¶åŒ–å¸§æ•°'] = worsened_frames
        self.reduction_analysis['æ”¹å–„ç‡'] = (improved_frames / len(self.data)) * 100
        self.reduction_analysis['æ¶åŒ–ç‡'] = (worsened_frames / len(self.data)) * 100
        
        # æ‰“å°æŠ¥å‘Š
        self._print_corrected_reduction_report()
        
    def _print_corrected_reduction_report(self):
        """æ‰“å°ä¿®æ­£çš„çœ¼éœ‡å‡ç¼“æ•ˆæœæŠ¥å‘Š"""
        print(f"\nğŸ“Š ä¿®æ­£çš„å‡ç¼“æ•ˆæœåˆ†æ:")
        print(f"   â€¢ å¹³å‡çœŸå®ä½ç§»: {self.reduction_analysis['å¹³å‡çœŸå®ä½ç§»']:.2f} åƒç´ ")
        print(f"   â€¢ å¹³å‡é¢„æµ‹ä½ç§»: {self.reduction_analysis['å¹³å‡é¢„æµ‹ä½ç§»']:.2f} åƒç´ ")
        print(f"   â€¢ å¹³å‡å…¬å…±åŒºåŸŸï¼ˆæœ‰æ•ˆå‡ç¼“ï¼‰: {self.reduction_analysis['å¹³å‡å…¬å…±åŒºåŸŸ']:.2f} åƒç´ ")
        print(f"   â€¢ å¹³å‡æ®‹ä½™çœ¼éœ‡: {self.reduction_analysis['å¹³å‡æ®‹ä½™çœ¼éœ‡']:.2f} åƒç´ ")
        print(f"   â€¢ å¹³å‡å¼‚å¸¸å¢å¼º: {self.reduction_analysis['å¹³å‡å¼‚å¸¸å¢å¼º']:.2f} åƒç´ ")
        print(f"   â€¢ å¹³å‡å‡ç¼“æ•ˆç‡: {self.reduction_analysis['å¹³å‡å‡ç¼“æ•ˆç‡']:.1f}%")
        
        print(f"\nğŸ“ˆ æœ€å¤§å€¼ç»Ÿè®¡:")
        print(f"   â€¢ æœ€å¤§çœŸå®ä½ç§»: {self.reduction_analysis['æœ€å¤§çœŸå®ä½ç§»']:.2f} åƒç´ ")
        print(f"   â€¢ æœ€å¤§é¢„æµ‹ä½ç§»: {self.reduction_analysis['æœ€å¤§é¢„æµ‹ä½ç§»']:.2f} åƒç´ ")
        print(f"   â€¢ æœ€å¤§æ®‹ä½™çœ¼éœ‡: {self.reduction_analysis['æœ€å¤§æ®‹ä½™çœ¼éœ‡']:.2f} åƒç´ ")
        print(f"   â€¢ æœ€å¤§å¼‚å¸¸å¢å¼º: {self.reduction_analysis['æœ€å¤§å¼‚å¸¸å¢å¼º']:.2f} åƒç´ ")
        
        print(f"\nâœ… æ”¹å–„ä¸æ¶åŒ–ç»Ÿè®¡:")
        print(f"   â€¢ æ”¹å–„å¸§æ•°: {self.reduction_analysis['æ”¹å–„å¸§æ•°']}/{len(self.data)}")
        print(f"   â€¢ æ”¹å–„ç‡: {self.reduction_analysis['æ”¹å–„ç‡']:.1f}%")
        print(f"   â€¢ æ¶åŒ–å¸§æ•°: {self.reduction_analysis['æ¶åŒ–å¸§æ•°']}/{len(self.data)}")
        print(f"   â€¢ æ¶åŒ–ç‡: {self.reduction_analysis['æ¶åŒ–ç‡']:.1f}%")

    def print_analysis_report(self):
        """æ‰“å°Xè½´UKFé¢„æµ‹åˆ†ææŠ¥å‘Šï¼ˆè°ƒæ•´NRMSEè¯„çº§æ ‡å‡†ï¼‰"""
        if not hasattr(self, 'metrics'):
            self.calculate_accuracy_metrics()
        
        print("\n" + "="*70)
        print("ğŸ¯ Xè½´çœ¼éœ‡UKFæ³¨è§†é¢„æµ‹å‡†ç¡®æ€§åˆ†ææŠ¥å‘Šï¼ˆè°ƒæ•´NRMSEè¯„çº§ï¼‰")
        print("="*70)
        
        # æ€»ä½“æ€§èƒ½è¯„çº§ï¼ˆåŸºäºä¿®æ­£çš„NRMSEå’Œå…¶ä»–ç»¼åˆæŒ‡æ ‡ï¼‰
        nrmse_corrected = self.metrics['Xè½´NRMSE_ä¿®æ­£']
        avg_error = self.metrics['å¹³å‡ç»å¯¹è¯¯å·®']
        correlation = self.metrics['Xè½´ç›¸å…³æ€§']
        r2 = self.metrics['Xè½´RÂ²']
        precision_10px = self.metrics['10åƒç´ å†…']
        
        # è°ƒæ•´åçš„NRMSEè¯„çº§æ ‡å‡†ï¼ˆè€ƒè™‘çœ¼åŠ¨é¢„æµ‹çš„å®é™…å›°éš¾åº¦ï¼‰
        if nrmse_corrected > 0.85:
            nrmse_grade = "å“è¶Š"
        elif nrmse_corrected > 0.75:
            nrmse_grade = "ä¼˜ç§€"
        elif nrmse_corrected > 0.60:
            nrmse_grade = "è‰¯å¥½"
        elif nrmse_corrected > 0.45:
            nrmse_grade = "å¯æ¥å—"
        else:
            nrmse_grade = "éœ€æ”¹è¿›"
        
        # ç»¼åˆè¯„çº§ï¼ˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡ï¼‰
        score = 0
        if nrmse_corrected > 0.60: score += 1
        if correlation > 0.85: score += 1
        if r2 > 0.70: score += 1
        if precision_10px > 50: score += 1
        if avg_error < 20: score += 1
        
        if score >= 4:
            overall_grade = "å“è¶Š â­â­â­â­â­+"
        elif score >= 3:
            overall_grade = "ä¼˜ç§€ â­â­â­â­â­"
        elif score >= 2:
            overall_grade = "è‰¯å¥½ â­â­â­â­"
        else:
            overall_grade = "éœ€æ”¹è¿› â­â­â­"
        
        print(f"\nğŸ† Xè½´UKFé¢„æµ‹ç»¼åˆè¯„çº§: {overall_grade}")
        print(f"   ä¿®æ­£NRMSE: {nrmse_corrected:.4f} ({nrmse_grade})")
        print(f"   å¹³å‡è¯¯å·®: {avg_error:.1f} åƒç´  (çº¦ {avg_error/37.8:.1f} mm)")
        print(f"   ğŸ“Š ç»¼åˆè¯„åˆ†: {score}/5 (NRMSE+ç›¸å…³æ€§+RÂ²+ç²¾åº¦+è¯¯å·®)")
        
        print(f"\nğŸ“ Xè½´è¯¯å·®ç»Ÿè®¡:")
        print(f"   â€¢ å¹³å‡ç»å¯¹è¯¯å·®: {self.metrics['å¹³å‡ç»å¯¹è¯¯å·®']:.1f} åƒç´ ")
        print(f"   â€¢ ä¸­ä½æ•°è¯¯å·®: {self.metrics['ä¸­ä½æ•°ç»å¯¹è¯¯å·®']:.1f} åƒç´ ")
        print(f"   â€¢ æœ€å°è¯¯å·®: {self.metrics['æœ€å°ç»å¯¹è¯¯å·®']:.1f} åƒç´ ")
        print(f"   â€¢ æœ€å¤§è¯¯å·®: {self.metrics['æœ€å¤§ç»å¯¹è¯¯å·®']:.1f} åƒç´ ")
        print(f"   â€¢ è¯¯å·®æ³¢åŠ¨: Â±{self.metrics['è¯¯å·®æ ‡å‡†å·®']:.1f} åƒç´ ")
        print(f"   â€¢ 95%ç½®ä¿¡åŒºé—´: {self.metrics['95%ç½®ä¿¡åŒºé—´']} åƒç´ ")
        print(f"   â€¢ RMSE: {self.metrics['Xè½´RMSE']:.1f} åƒç´ ")
        print(f"   â€¢ MAE: {self.metrics['Xè½´MAE']:.1f} åƒç´ ")
        
        print(f"\nğŸ“Š NRMSEå¯¹æ¯”åˆ†æ:")
        print(f"   â€¢ ä¿®æ­£NRMSE: {self.metrics['Xè½´NRMSE_ä¿®æ­£']:.4f} (å…¬å¼: 1 - ||Yref-Y|| / ||Yref-mean(Yref)||)")
        print(f"   â€¢ ä¼ ç»ŸNRMSE(åŸºäºèŒƒå›´): {self.metrics['Xè½´NRMSE_åŸå§‹']:.4f} (RMSE/æ•°æ®èŒƒå›´)")
        
        # è°ƒæ•´åçš„NRMSEè¯„çº§è¯´æ˜
        print(f"\nğŸ¯ è°ƒæ•´åçš„NRMSEè¯„çº§æ ‡å‡†ï¼ˆé’ˆå¯¹çœ¼åŠ¨é¢„æµ‹ï¼‰:")
        print(f"   â€¢ >0.85: å“è¶Š | 0.75-0.85: ä¼˜ç§€ | 0.60-0.75: è‰¯å¥½")
        print(f"   â€¢ 0.45-0.60: å¯æ¥å— | <0.45: éœ€æ”¹è¿›")
        print(f"   â€¢ æ‚¨çš„ç»“æœ: {nrmse_corrected:.4f} â†’ {nrmse_grade}")
        
        if 'å¹³å‡æ€»è¯¯å·®' in self.metrics:
            print(f"\nğŸ“ æ€»è¯¯å·®ç»Ÿè®¡ï¼ˆå«Yè½´ï¼‰:")
            print(f"   â€¢ å¹³å‡æ€»è¯¯å·®: {self.metrics['å¹³å‡æ€»è¯¯å·®']:.1f} åƒç´ ")
            print(f"   â€¢ æœ€å¤§æ€»è¯¯å·®: {self.metrics['æœ€å¤§æ€»è¯¯å·®']:.1f} åƒç´ ")
        
        print(f"\nğŸ‘ï¸ è§†è§’ç²¾åº¦:")
        print(f"   â€¢ å¹³å‡è§†è§’è¯¯å·®: {self.metrics['å¹³å‡è§†è§’è¯¯å·®']:.2f}Â°")
        print(f"   â€¢ æœ€å°è§†è§’è¯¯å·®: {self.metrics['æœ€å°è§†è§’è¯¯å·®']:.2f}Â°")
        print(f"   â€¢ æœ€å¤§è§†è§’è¯¯å·®: {self.metrics['æœ€å¤§è§†è§’è¯¯å·®']:.2f}Â°")
        
        print(f"\nğŸ¯ Xè½´ç²¾åº¦åˆ†å¸ƒ:")
        print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("   â”‚ è¯¯å·®èŒƒå›´    â”‚ ç™¾åˆ†æ¯”   â”‚ å¯è§†åŒ–             â”‚")
        print("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        thresholds = [1, 2, 3, 5, 10, 15, 20, 30, 50]
        for t in thresholds:
            percent = self.metrics[f'{t}åƒç´ å†…']
            bar = 'â–ˆ' * int(percent / 2.5)
            status = ""
            if t <= 5 and percent > 25:
                status = " ğŸ†"
            elif t <= 10 and percent > 50:
                status = " â­"
            elif t <= 20 and percent > 80:
                status = " âœ…"
            print(f"   â”‚ â‰¤{t:2d} åƒç´    â”‚ {percent:5.1f}%   â”‚ {bar:<20} â”‚{status}")
        
        print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        print(f"\nğŸ“Š Xè½´UKFé¢„æµ‹è´¨é‡:")
        print(f"   â€¢ ç›¸å…³æ€§: {self.metrics['Xè½´ç›¸å…³æ€§']:.3f} {'ğŸ†' if self.metrics['Xè½´ç›¸å…³æ€§'] > 0.9 else 'â­' if self.metrics['Xè½´ç›¸å…³æ€§'] > 0.8 else ''}")
        print(f"   â€¢ RÂ²: {self.metrics['Xè½´RÂ²']:.3f} {'ğŸ†' if self.metrics['Xè½´RÂ²'] > 0.8 else 'â­' if self.metrics['Xè½´RÂ²'] > 0.7 else ''}")
        
        print(f"\nâš–ï¸ Xè½´ç³»ç»Ÿæ€§åå·®:")
        bias_x = self.metrics['Xè½´ç³»ç»Ÿåå·®']
        print(f"   â€¢ åå·®: {bias_x:+.1f} åƒç´  {'(åå³)' if bias_x > 0 else '(åå·¦)'}")
        
        if 'UKFé¢„æµ‹å¹³æ»‘åº¦' in self.metrics:
            print(f"\nğŸŒŠ Xè½´UKFç¨³å®šæ€§æŒ‡æ ‡:")
            print(f"   â€¢ é¢„æµ‹å¹³æ»‘åº¦: {self.metrics['UKFé¢„æµ‹å¹³æ»‘åº¦']:.1f} åƒç´ /å¸§")
            print(f"   â€¢ é¢„æµ‹æŠ–åŠ¨åº¦: {self.metrics['UKFé¢„æµ‹æŠ–åŠ¨åº¦']:.1f} åƒç´ ")
        
        # æ–°å¢ï¼šæ€§èƒ½äº®ç‚¹æ€»ç»“
        print(f"\nâœ¨ æ€§èƒ½äº®ç‚¹æ€»ç»“:")
        highlights = []
        if self.metrics['Xè½´ç›¸å…³æ€§'] > 0.9:
            highlights.append(f"ğŸ¯ å¼ºç›¸å…³æ€§ ({self.metrics['Xè½´ç›¸å…³æ€§']:.3f})")
        if self.metrics['Xè½´RÂ²'] > 0.8:
            highlights.append(f"ğŸ“ˆ é«˜è§£é‡Šåº¦ (RÂ²={self.metrics['Xè½´RÂ²']:.3f})")
        if self.metrics['10åƒç´ å†…'] > 50:
            highlights.append(f"ğŸª é«˜ç²¾åº¦ ({self.metrics['10åƒç´ å†…']:.1f}%åœ¨Â±10pxå†…)")
        if self.metrics['å¹³å‡ç»å¯¹è¯¯å·®'] < 20:
            highlights.append(f"ğŸ“ ä½è¯¯å·® (å¹³å‡{self.metrics['å¹³å‡ç»å¯¹è¯¯å·®']:.1f}px)")
        
        for highlight in highlights:
            print(f"   â€¢ {highlight}")
        
        if len(highlights) >= 3:
            print(f"   ğŸ† æ€»ä½“è¡¨ç°ï¼šæ‚¨çš„UKFç³»ç»Ÿè¡¨ç°ä¼˜ç§€ï¼")
        elif len(highlights) >= 2:
            print(f"   â­ æ€»ä½“è¡¨ç°ï¼šæ‚¨çš„UKFç³»ç»Ÿè¡¨ç°è‰¯å¥½ï¼")
        else:
            print(f"   ğŸ“Š æ€»ä½“è¡¨ç°ï¼šæ‚¨çš„UKFç³»ç»Ÿæœ‰æ”¹è¿›ç©ºé—´ã€‚")

    # ==========================================
    # å¯è§†åŒ–å‡½æ•°ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½å¹¶å¢å¼ºï¼‰
    # ==========================================
    
    def create_page1_tracking_and_error(self):
        """ç¬¬1é¡µï¼šXè½´è·Ÿè¸ªæ•ˆæœå’Œè¯¯å·®åˆ†æ (2ä¸ªå›¾è¡¨)"""
        fig = plt.figure(figsize=(24, 12))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬1é¡µï¼šè·Ÿè¸ªæ•ˆæœä¸è¯¯å·®åˆ†æ', fontsize=24, y=0.95)
        
        gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.25)
        
        # 1. Xè½´é¢„æµ‹è·Ÿè¸ªæ•ˆæœ
        ax1 = fig.add_subplot(gs[0, 0])
        
        ax1.plot(self.data['frameId'], self.data['predictedX'], 'r-', linewidth=3, 
                label='UKFé¢„æµ‹', alpha=0.8, zorder=1)
        ax1.plot(self.data['frameId'], self.data['actualX'], 'b--', linewidth=2.5, 
                label='çœŸå®å€¼', alpha=0.9, zorder=2)
        
        # å¦‚æœæœ‰å¹³æ»‘æ•°æ®ï¼Œä¹Ÿæ˜¾ç¤ºå¹³æ»‘è½¨è¿¹
        if 'å¹³æ»‘_X' in self.data.columns:
            ax1.plot(self.data['frameId'], self.data['å¹³æ»‘_X'], 'g:', linewidth=2, 
                    label='å¹³æ»‘çœŸå®å€¼', alpha=0.7, zorder=1)
        
        ax1.fill_between(self.data['frameId'], self.data['actualX'], self.data['predictedX'], 
                        alpha=0.2, color='gray', label='è¯¯å·®åŒºåŸŸ', zorder=0)
        
        ax1.set_xlabel('å¸§ID', fontsize=18)
        ax1.set_ylabel('Xåæ ‡ (åƒç´ )', fontsize=18)
        ax1.set_title('Xè½´UKFé¢„æµ‹è·Ÿè¸ªæ•ˆæœï¼ˆå«è½¨è¿¹åˆ†æï¼‰', fontsize=20, pad=20)
        ax1.legend(fontsize=16, loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ è½¨è¿¹ç‰¹å¾ä¿¡æ¯
        if self.trajectory_analysis:
            trajectory_info = f'çœ¼éœ‡ç±»å‹: {", ".join(self.trajectory_analysis.get("çœ¼éœ‡ç±»å‹", ["æœªçŸ¥"]))}\n'
            trajectory_info += f'ä¸»é¢‘ç‡: {self.trajectory_analysis.get("ä¸»é¢‘ç‡", 0):.2f} Hz\n'
            trajectory_info += f'å¼ºåº¦ç­‰çº§: {self.trajectory_analysis.get("å¼ºåº¦ç­‰çº§", "æœªçŸ¥")}'
            ax1.text(0.02, 0.95, trajectory_info, 
                    transform=ax1.transAxes, fontsize=12, 
                    verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcyan', alpha=0.8))
        
        # 2. Xè½´è¯¯å·®æ—¶åºåˆ†æ
        ax2 = fig.add_subplot(gs[0, 1])
        
        ax2.plot(self.data['frameId'], self.data['è¯¯å·®_X'], alpha=0.7, color='red', 
                linewidth=2, label='Xè½´è¯¯å·®')
        
        ax2.axhline(y=0, color='black', linestyle='-', linewidth=2, alpha=0.8)
        ax2.axhline(y=10, color='green', linestyle='--', linewidth=2, alpha=0.8, label='Â±10px')
        ax2.axhline(y=-10, color='green', linestyle='--', linewidth=2, alpha=0.8)
        ax2.axhline(y=20, color='orange', linestyle='--', linewidth=2, alpha=0.8, label='Â±20px')
        ax2.axhline(y=-20, color='orange', linestyle='--', linewidth=2, alpha=0.8)
        
        if 'è¯¯å·®_ç§»åŠ¨å¹³å‡' in self.data.columns:
            ax2.plot(self.data['frameId'], self.data['è¯¯å·®_ç§»åŠ¨å¹³å‡'], color='darkred', 
                    linewidth=4, label='ç§»åŠ¨å¹³å‡', alpha=0.9)
        
        ax2.set_xlabel('å¸§ID', fontsize=18)
        ax2.set_ylabel('Xè½´è¯¯å·® (åƒç´ )', fontsize=18)
        ax2.set_title('Xè½´é¢„æµ‹è¯¯å·®å˜åŒ–è¶‹åŠ¿', fontsize=20, pad=20)
        ax2.legend(loc='upper right', fontsize=14)
        ax2.grid(True, alpha=0.3)
        ax2.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ è¯¯å·®ç»Ÿè®¡ä¿¡æ¯
        error_stats_text = f'å¹³å‡è¯¯å·®: {self.metrics["å¹³å‡ç»å¯¹è¯¯å·®"]:.1f}px\nä¸­ä½æ•°: {self.metrics["ä¸­ä½æ•°ç»å¯¹è¯¯å·®"]:.1f}px\næ ‡å‡†å·®: {self.metrics["è¯¯å·®æ ‡å‡†å·®"]:.1f}px'
        ax2.text(0.02, 0.95, error_stats_text, 
                transform=ax2.transAxes, fontsize=14, 
                verticalalignment='top',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8))
        
        plt.tight_layout()
        plt.show()

    def create_page2_precision_analysis(self):
        """ç¬¬2é¡µï¼šXè½´ç²¾åº¦åˆ†æ (2ä¸ªå›¾è¡¨)"""
        fig = plt.figure(figsize=(24, 12))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬2é¡µï¼šç²¾åº¦åˆ†æ', fontsize=24, y=0.95)
        
        gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.25)
        
        # 1. è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
        ax1 = fig.add_subplot(gs[0, 0])
        
        bins = np.concatenate([
            np.arange(0, 10, 1),      
            np.arange(10, 30, 2),     
            np.arange(30, 60, 5),     
            np.arange(60, 100, 10),   
            [120, 150, 200]           
        ])
        
        n, bins, patches = ax1.hist(self.data['ç»å¯¹è¯¯å·®_X'], bins=bins, alpha=0.8, 
                                   edgecolor='darkblue', linewidth=2)
        
        # æ ¹æ®è¯¯å·®å¤§å°ç€è‰²
        for i, patch in enumerate(patches):
            if bins[i] < 3:
                patch.set_facecolor('#27ae60')  
                patch.set_alpha(0.9)
            elif bins[i] < 5:
                patch.set_facecolor('#2ecc71')  
                patch.set_alpha(0.8)
            elif bins[i] < 10:
                patch.set_facecolor('#3498db')  
                patch.set_alpha(0.8)
            elif bins[i] < 20:
                patch.set_facecolor('#f39c12')  
                patch.set_alpha(0.8)
            elif bins[i] < 50:
                patch.set_facecolor('#e67e22')  
                patch.set_alpha(0.8)
            else:
                patch.set_facecolor('#e74c3c')  
                patch.set_alpha(0.8)
        
        ax1.axvline(self.data['ç»å¯¹è¯¯å·®_X'].mean(), color='red', linestyle='--', 
                   linewidth=3, label=f'å¹³å‡: {self.data["ç»å¯¹è¯¯å·®_X"].mean():.1f}px')
        ax1.axvline(self.data['ç»å¯¹è¯¯å·®_X'].median(), color='green', linestyle='--', 
                   linewidth=3, label=f'ä¸­ä½æ•°: {self.data["ç»å¯¹è¯¯å·®_X"].median():.1f}px')
        
        ax1.set_xlabel('ç»å¯¹è¯¯å·® (åƒç´ )', fontsize=18)
        ax1.set_ylabel('é¢‘æ¬¡', fontsize=18)
        ax1.set_title('Xè½´è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾', fontsize=20, pad=20)
        ax1.legend(fontsize=16)
        ax1.grid(True, alpha=0.3, axis='y')
        ax1.set_xlim(0, min(100, self.data['ç»å¯¹è¯¯å·®_X'].max() * 1.1))
        ax1.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ ä¿®æ­£NRMSEå’Œè½¨è¿¹ä¿¡æ¯
        stats_text = f'RMSE: {self.metrics["Xè½´RMSE"]:.1f}px\nMAE: {self.metrics["Xè½´MAE"]:.1f}px\nä¿®æ­£NRMSE: {self.metrics["Xè½´NRMSE_ä¿®æ­£"]:.4f}'
        if self.trajectory_analysis.get('å¼ºåº¦ç­‰çº§'):
            stats_text += f'\nçœ¼éœ‡å¼ºåº¦: {self.trajectory_analysis["å¼ºåº¦ç­‰çº§"]}'
        ax1.text(0.7, 0.85, stats_text, transform=ax1.transAxes, 
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                fontsize=14, verticalalignment='top')
        
        # 2. ç²¾åº¦ç­‰çº§é¥¼å›¾
        ax2 = fig.add_subplot(gs[0, 1])
        
        thresholds = [5, 10, 15, 20, 50, np.inf]
        labels = ['<5px\n(æè‡´)', '5-10px\n(ä¼˜ç§€)', '10-15px\n(è‰¯å¥½)', 
                 '15-20px\n(åˆæ ¼)', '20-50px\n(è¾ƒå·®)', '>50px\n(å·®)']
        colors_pie = ['#27ae60', '#2ecc71', '#3498db', '#52c41a', '#f39c12', '#e74c3c']
        
        counts = []
        for i in range(len(thresholds)):
            if i == 0:
                count = (self.data['ç»å¯¹è¯¯å·®_X'] < thresholds[i]).sum()
            else:
                count = ((self.data['ç»å¯¹è¯¯å·®_X'] >= thresholds[i-1]) & 
                        (self.data['ç»å¯¹è¯¯å·®_X'] < thresholds[i])).sum()
            counts.append(count)
        
        non_zero = [(c, l, col) for c, l, col in zip(counts, labels, colors_pie) if c > 0]
        if non_zero:
            counts_nz, labels_nz, colors_nz = zip(*non_zero)
            
            wedges, texts, autotexts = ax2.pie(counts_nz, labels=labels_nz, colors=colors_nz, 
                                               autopct=lambda pct: f'{pct:.1f}%\n({int(pct*len(self.data)/100)})', 
                                               startangle=90, pctdistance=0.85, labeldistance=1.1)
            
            for text in texts:
                text.set_fontsize(16)
                text.set_weight('bold')
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_weight('bold')
                autotext.set_fontsize(15)
        
        ax2.set_title('Xè½´ç²¾åº¦ç­‰çº§åˆ†å¸ƒ', fontsize=20, pad=20)
        
        # æ·»åŠ NRMSEè¯„ä»·å’Œè½¨è¿¹ä¿¡æ¯
        nrmse_corrected = self.metrics['Xè½´NRMSE_ä¿®æ­£']
        nrmse_eval = ""
        if nrmse_corrected > 0.85:
            nrmse_eval = "å“è¶Š"
        elif nrmse_corrected > 0.75:
            nrmse_eval = "ä¼˜ç§€"
        elif nrmse_corrected > 0.60:
            nrmse_eval = "è‰¯å¥½"
        else:
            nrmse_eval = "éœ€æ”¹è¿›"
        
        eval_text = f'NRMSEè¯„ä»·: {nrmse_eval}'
        if self.trajectory_analysis.get('çœ¼éœ‡æ¨¡å¼'):
            eval_text += f'\nçœ¼éœ‡æ¨¡å¼: {self.trajectory_analysis["çœ¼éœ‡æ¨¡å¼"]}'
        
        ax2.text(0.5, -0.15, eval_text, 
                transform=ax2.transAxes, fontsize=16, 
                ha='center', weight='bold',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
        
        plt.tight_layout()
        plt.show()
    
    def create_page3_enhanced_nystagmus_analysis(self):
        """ç¬¬3é¡µï¼šå¢å¼ºç‰ˆçœ¼éœ‡ç‰¹æ€§åˆ†æ (2ä¸ªå›¾è¡¨)"""
        fig = plt.figure(figsize=(24, 12))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬3é¡µï¼šæ·±åº¦çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æ', fontsize=24, y=0.95)
        
        gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.25)
        
        # 1. Xè½´çœ¼åŠ¨é€Ÿåº¦å’ŒåŠ é€Ÿåº¦åˆ†æ
        ax1 = fig.add_subplot(gs[0, 0])
        
        # åŒYè½´ï¼šé€Ÿåº¦å’ŒåŠ é€Ÿåº¦
        ax1_twin = ax1.twinx()
        
        # ç»˜åˆ¶é€Ÿåº¦
        line1 = ax1.plot(self.data['frameId'], self.data['Xè½´çœ¼åŠ¨é€Ÿåº¦'], 'purple', 
                        linewidth=2, alpha=0.8, label='çœ¼åŠ¨é€Ÿåº¦')
        
        # ç»˜åˆ¶åŠ é€Ÿåº¦ï¼ˆç¼©æ”¾ä»¥ä¾¿æ˜¾ç¤ºï¼‰
        accel_scaled = self.data['Xè½´åŠ é€Ÿåº¦'] / 10  # ç¼©æ”¾10å€ä»¥ä¾¿æ˜¾ç¤º
        line2 = ax1_twin.plot(self.data['frameId'], accel_scaled, 'orange', 
                             linewidth=2, alpha=0.8, label='åŠ é€Ÿåº¦(/10)')
        
        # æ·»åŠ é€Ÿåº¦é˜ˆå€¼çº¿
        ax1.axhline(y=100, color='green', linestyle='--', linewidth=2, alpha=0.6, label='ä½é€Ÿé˜ˆå€¼')
        ax1.axhline(y=300, color='orange', linestyle='--', linewidth=2, alpha=0.6, label='ä¸­é€Ÿé˜ˆå€¼')
        ax1.axhline(y=500, color='red', linestyle='--', linewidth=2, alpha=0.6, label='é«˜é€Ÿé˜ˆå€¼')
        
        # æ ‡è®°é«˜é€Ÿçœ¼åŠ¨ç‚¹
        high_speed_points = self.data[self.data['Xè½´çœ¼åŠ¨é€Ÿåº¦'] > 500]
        if len(high_speed_points) > 0:
            ax1.scatter(high_speed_points['frameId'], high_speed_points['Xè½´çœ¼åŠ¨é€Ÿåº¦'], 
                       color='red', s=60, alpha=0.8, label='é«˜é€Ÿçœ¼åŠ¨', zorder=5)
        
        ax1.set_xlabel('å¸§ID', fontsize=18)
        ax1.set_ylabel('é€Ÿåº¦ (åƒç´ /ç§’)', fontsize=18, color='purple')
        ax1_twin.set_ylabel('åŠ é€Ÿåº¦ (Ã—10 åƒç´ /ç§’Â²)', fontsize=18, color='orange')
        ax1.set_title('Xè½´çœ¼åŠ¨åŠ¨åŠ›å­¦åˆ†æ', fontsize=20, pad=20)
        
        # åˆå¹¶å›¾ä¾‹
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax1_twin.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, fontsize=12, loc='upper right')
        
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='both', which='major', labelsize=16)
        ax1_twin.tick_params(axis='y', which='major', labelsize=16)
        
        # æ·»åŠ è½¨è¿¹ç‰¹å¾ä¿¡æ¯
        if self.trajectory_analysis:
            trajectory_info = f'çœ¼éœ‡æ¨¡å¼: {self.trajectory_analysis.get("çœ¼éœ‡æ¨¡å¼", "æœªçŸ¥")}\n'
            trajectory_info += f'å¹³å‡é€Ÿåº¦: {self.trajectory_analysis.get("å¹³å‡é€Ÿåº¦", 0):.1f} px/s\n'
            trajectory_info += f'å¼ºåº¦è¯„åˆ†: {self.trajectory_analysis.get("å¼ºåº¦è¯„åˆ†", 0):.1f}/10\n'
            trajectory_info += f'è¿åŠ¨è¿ç»­æ€§: {self.trajectory_analysis.get("è¿åŠ¨è¿ç»­æ€§", 0)*100:.1f}%'
            ax1.text(0.02, 0.95, trajectory_info, 
                    transform=ax1.transAxes, fontsize=12, 
                    verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
        
        # 2. Xè½´é¢‘è°±å’Œæ³¢å½¢ç‰¹å¾åˆ†æ
        ax2 = fig.add_subplot(gs[0, 1])
        
        # æ‰§è¡ŒFFTåˆ†æ
        if 'å¹³æ»‘_X' in self.data.columns:
            signal = self.data['å¹³æ»‘_X'].values - np.mean(self.data['å¹³æ»‘_X'].values)
        else:
            signal = self.data['actualX'].values - np.mean(self.data['actualX'].values)
            
        fft_result = fft(signal)
        freqs = fftfreq(len(signal), 1/self.fps)
        
        # åªæ˜¾ç¤ºæ­£é¢‘ç‡éƒ¨åˆ†
        positive_freqs = freqs[freqs > 0]
        fft_magnitude = np.abs(fft_result[freqs > 0])
        
        # ç»˜åˆ¶é¢‘è°±ï¼ˆé™åˆ¶åœ¨çœ¼éœ‡ç›¸å…³é¢‘ç‡èŒƒå›´ï¼‰
        freq_mask = positive_freqs <= 20
        display_freqs = positive_freqs[freq_mask]
        display_magnitude = fft_magnitude[freq_mask]
        
        ax2.plot(display_freqs, display_magnitude, 'b-', linewidth=2, alpha=0.8, label='é¢‘è°±')
        
        # æ ‡è®°ä¸»é¢‘ç‡å’Œè°æ³¢
        if self.trajectory_analysis.get('ä¸»é¢‘ç‡', 0) > 0:
            main_freq = self.trajectory_analysis['ä¸»é¢‘ç‡']
            ax2.axvline(x=main_freq, color='red', linestyle='--', linewidth=3, 
                       label=f'ä¸»é¢‘ç‡: {main_freq:.2f} Hz')
            
            # æ ‡è®°è°æ³¢
            for i in range(2, 5):
                harmonic_freq = main_freq * i
                if harmonic_freq <= 20:
                    ax2.axvline(x=harmonic_freq, color='orange', linestyle=':', 
                               linewidth=2, alpha=0.7, label=f'{i}æ¬¡è°æ³¢' if i == 2 else '')
        
        # æ ‡è®°é¢‘å¸¦
        freq_bands = [(0, 1, 'lightblue', 'è¶…ä½é¢‘'), (1, 3, 'lightgreen', 'ä½é¢‘'), 
                     (3, 7, 'lightyellow', 'ä¸­é¢‘'), (7, 15, 'lightcoral', 'é«˜é¢‘')]
        
        for low, high, color, name in freq_bands:
            ax2.axvspan(low, high, alpha=0.2, color=color, label=name if low == 0 else '')
        
        ax2.set_xlabel('é¢‘ç‡ (Hz)', fontsize=18)
        ax2.set_ylabel('å¹…åº¦', fontsize=18)
        ax2.set_title('Xè½´çœ¼éœ‡é¢‘è°±åˆ†æï¼ˆå«é¢‘å¸¦åˆ’åˆ†ï¼‰', fontsize=20, pad=20)
        ax2.set_xlim(0, 20)
        ax2.legend(fontsize=12, loc='upper right')
        ax2.grid(True, alpha=0.3)
        ax2.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ é¢‘ç‡å’Œæ³¢å½¢ç‰¹å¾ä¿¡æ¯
        if self.trajectory_analysis:
            freq_info = f'é¢‘ç‡åˆ†ç±»: {self.trajectory_analysis.get("é¢‘ç‡åˆ†ç±»", "æœªçŸ¥")}\n'
            freq_info += f'é¢‘ç‡ç¨³å®šæ€§: {self.trajectory_analysis.get("é¢‘ç‡ç¨³å®šæ€§", 0):.3f}\n'
            freq_info += f'æ³¢å½¢ç±»å‹: {self.trajectory_analysis.get("æ³¢å½¢ç±»å‹", "æœªçŸ¥")}\n'
            freq_info += f'æ³¢å½¢å¯¹ç§°æ€§: {self.trajectory_analysis.get("æ³¢å½¢å¯¹ç§°æ€§", 0):.3f}\n'
            freq_info += f'æ³¢å½¢å‘¨æœŸæ€§: {self.trajectory_analysis.get("æ³¢å½¢å‘¨æœŸæ€§", 0):.3f}'
            
            ax2.text(0.02, 0.98, freq_info, 
                    transform=ax2.transAxes, fontsize=11, 
                    verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))
        
        plt.tight_layout()
        plt.show()
    
    def create_page4_scatter_analysis(self):
        """ç¬¬4é¡µï¼šXè½´æ•£ç‚¹åˆ†æ (2ä¸ªå›¾è¡¨)"""
        fig = plt.figure(figsize=(24, 12))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬4é¡µï¼šç›¸å…³æ€§ä¸é¢„æµ‹è´¨é‡åˆ†æ', fontsize=24, y=0.95)
        
        gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.25)
        
        # 1. çœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾ï¼ˆå¢å¼ºç‰ˆï¼‰
        ax1 = fig.add_subplot(gs[0, 0])
        
        # æ ¹æ®è¯¯å·®å¤§å°ç€è‰²æ•£ç‚¹
        colors = self.data['ç»å¯¹è¯¯å·®_X']
        scatter = ax1.scatter(self.data['actualX'], self.data['predictedX'], 
                             c=colors, cmap='viridis_r', alpha=0.6, s=30)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax1)
        cbar.set_label('ç»å¯¹è¯¯å·® (åƒç´ )', fontsize=14)
        
        # æ·»åŠ ç†æƒ³é¢„æµ‹çº¿ï¼ˆy=xï¼‰
        min_val = min(self.data['actualX'].min(), self.data['predictedX'].min())
        max_val = max(self.data['actualX'].max(), self.data['predictedX'].max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=3, 
                label='ç†æƒ³é¢„æµ‹çº¿', alpha=0.8)
        
        # æ·»åŠ å›å½’çº¿
        z = np.polyfit(self.data['actualX'], self.data['predictedX'], 1)
        p = np.poly1d(z)
        ax1.plot([min_val, max_val], p([min_val, max_val]), 'g-', linewidth=3, 
                label=f'å›å½’çº¿: y={z[0]:.3f}x+{z[1]:.1f}', alpha=0.8)
        
        # æ·»åŠ ç½®ä¿¡åŒºé—´
        residuals = self.data['predictedX'] - p(self.data['actualX'])
        mse = np.mean(residuals**2)
        std_err = np.sqrt(mse)
        
        confidence_band = 1.96 * std_err  # 95%ç½®ä¿¡åŒºé—´
        ax1.fill_between([min_val, max_val], 
                        p([min_val, max_val]) - confidence_band,
                        p([min_val, max_val]) + confidence_band,
                        alpha=0.2, color='green', label='95%ç½®ä¿¡åŒºé—´')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = f'ç›¸å…³ç³»æ•°: {self.metrics["Xè½´ç›¸å…³æ€§"]:.3f}\nRÂ²: {self.metrics["Xè½´RÂ²"]:.3f}\nä¿®æ­£NRMSE: {self.metrics["Xè½´NRMSE_ä¿®æ­£"]:.4f}'
        if self.trajectory_analysis.get('æ–¹å‘æ¨¡å¼'):
            stats_text += f'\næ–¹å‘æ¨¡å¼: {self.trajectory_analysis["æ–¹å‘æ¨¡å¼"]}'
        
        ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes, 
                fontsize=14, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
                verticalalignment='top')
        
        ax1.set_xlabel('çœŸå®Xåæ ‡ (åƒç´ )', fontsize=18)
        ax1.set_ylabel('é¢„æµ‹Xåæ ‡ (åƒç´ )', fontsize=18)
        ax1.set_title('Xè½´çœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾ï¼ˆè‰²å½©ç¼–ç è¯¯å·®ï¼‰', fontsize=20, pad=20)
        ax1.legend(fontsize=14, loc='lower right')
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='both', which='major', labelsize=16)
        
        # 2. çœ¼éœ‡æ–¹å‘æ€§å’Œä½ç§»åˆ†æ
        ax2 = fig.add_subplot(gs[0, 1])
        
        # è®¡ç®—ç›¸å¯¹äºä¸­å¿ƒä½ç½®çš„ä½ç§»
        center_pos = np.mean(self.data['actualX'])
        displacement_from_center = self.data['actualX'] - center_pos
        
        # åˆ›å»ºæ–¹å‘æ€§æ•£ç‚¹å›¾ï¼ˆæ—¶é—´ vs ä½ç§»ï¼‰
        # æ ¹æ®é€Ÿåº¦æ–¹å‘ç€è‰²
        velocity_colors = np.where(self.data['é€Ÿåº¦_X'] > 0, 'red', 'blue')
        velocity_colors = np.where(np.abs(self.data['é€Ÿåº¦_X']) < 10, 'gray', velocity_colors)
        
        # ç»˜åˆ¶æ•£ç‚¹ï¼Œæ ¹æ®è¿åŠ¨æ–¹å‘ç€è‰²
        for direction, color, label in [('right', 'red', 'å³å‘è¿åŠ¨'), 
                                       ('left', 'blue', 'å·¦å‘è¿åŠ¨'), 
                                       ('static', 'gray', 'ç›¸å¯¹é™æ­¢')]:
            if direction == 'right':
                mask = self.data['é€Ÿåº¦_X'] > 10
            elif direction == 'left':
                mask = self.data['é€Ÿåº¦_X'] < -10
            else:
                mask = np.abs(self.data['é€Ÿåº¦_X']) <= 10
            
            if np.any(mask):
                ax2.scatter(self.data.loc[mask, 'frameId'], 
                           displacement_from_center[mask],
                           c=color, alpha=0.6, s=20, label=label)
        
        # æ·»åŠ ä¸­å¿ƒçº¿
        ax2.axhline(y=0, color='black', linestyle='-', linewidth=2, alpha=0.8, label='ä¸­å¿ƒä½ç½®')
        
        # æ·»åŠ è¿åŠ¨èŒƒå›´çº¿
        if self.trajectory_analysis:
            rightward_extent = self.trajectory_analysis.get('å³å‘æœ€å¤§ä½ç§»', 0)
            leftward_extent = self.trajectory_analysis.get('å·¦å‘æœ€å¤§ä½ç§»', 0)
            ax2.axhline(y=rightward_extent, color='red', linestyle='--', 
                       linewidth=2, alpha=0.7, label=f'å³å‘è¾¹ç•Œ: +{rightward_extent:.1f}px')
            ax2.axhline(y=-leftward_extent, color='blue', linestyle='--', 
                       linewidth=2, alpha=0.7, label=f'å·¦å‘è¾¹ç•Œ: -{leftward_extent:.1f}px')
        
        ax2.set_xlabel('å¸§ID', fontsize=18)
        ax2.set_ylabel('ç›¸å¯¹ä¸­å¿ƒä½ç§» (åƒç´ )', fontsize=18)
        ax2.set_title('Xè½´çœ¼éœ‡æ–¹å‘æ€§å’Œä½ç§»åˆ†æ', fontsize=20, pad=20)
        ax2.legend(fontsize=12, loc='upper right')
        ax2.grid(True, alpha=0.3)
        ax2.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ æ–¹å‘æ€§ç»Ÿè®¡ä¿¡æ¯
        if self.trajectory_analysis:
            direction_info = f'å³å‘è¿åŠ¨: {self.trajectory_analysis.get("å³å‘è¿åŠ¨æ¯”ä¾‹", 0)*100:.1f}%\n'
            direction_info += f'å·¦å‘è¿åŠ¨: {self.trajectory_analysis.get("å·¦å‘è¿åŠ¨æ¯”ä¾‹", 0)*100:.1f}%\n'
            direction_info += f'ç›¸å¯¹é™æ­¢: {self.trajectory_analysis.get("é™æ­¢æ¯”ä¾‹", 0)*100:.1f}%\n'
            direction_info += f'æ–¹å‘æŒç»­æ€§: {self.trajectory_analysis.get("æ–¹å‘æŒç»­æ€§", 0):.3f}\n'
            direction_info += f'æ–¹å‘åå‘æ€§: {self.trajectory_analysis.get("æ–¹å‘åå‘æ€§", 0):.3f}'
            
            ax2.text(0.02, 0.98, direction_info, 
                    transform=ax2.transAxes, fontsize=12, 
                    verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcyan', alpha=0.8))
        
        plt.tight_layout()
        plt.show()
        
    def create_page5_corrected_reduction_analysis(self):
        """ç¬¬5é¡µï¼šä¿®æ­£çš„çœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æ"""
        fig = plt.figure(figsize=(24, 14))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬5é¡µï¼šçœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰', fontsize=24, y=0.96)
        
        gs = fig.add_gridspec(2, 1, hspace=0.35, height_ratios=[1, 1])
        
        # 1. åŒºåŸŸåˆ†è§£å †å å›¾
        ax1 = fig.add_subplot(gs[0, 0])
        
        # ç»˜åˆ¶å †å é¢ç§¯å›¾
        ax1.fill_between(self.data['frameId'], 0, self.data['å…¬å…±åŒºåŸŸ_å‡ç¼“'], 
                        alpha=0.8, color='green', label='å…¬å…±åŒºåŸŸï¼ˆæœ‰æ•ˆå‡ç¼“ï¼‰')
        ax1.fill_between(self.data['frameId'], self.data['å…¬å…±åŒºåŸŸ_å‡ç¼“'], 
                        self.data['å…¬å…±åŒºåŸŸ_å‡ç¼“'] + self.data['æ®‹ä½™çœ¼éœ‡'], 
                        alpha=0.8, color='orange', label='æ®‹ä½™çœ¼éœ‡')
        ax1.fill_between(self.data['frameId'], self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'], 
                        self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'] + self.data['å¼‚å¸¸å¢å¼º'], 
                        alpha=0.8, color='red', label='å¼‚å¸¸å¢å¼º')
        
        # æ·»åŠ è¾¹ç•Œçº¿
        ax1.plot(self.data['frameId'], self.data['çœŸå®ä½ç§»_ç»å¯¹å€¼'], 'b-', 
                linewidth=3, label='çœŸå®çœ¼éœ‡è¾¹ç•Œ', alpha=0.9)
        ax1.plot(self.data['frameId'], self.data['é¢„æµ‹ä½ç§»_ç»å¯¹å€¼'], 'r--', 
                linewidth=3, label='é¢„æµ‹ä½ç§»è¾¹ç•Œ', alpha=0.9)
        
        ax1.set_xlabel('å¸§ID', fontsize=18)
        ax1.set_ylabel('ä½ç§»å¹…åº¦ (åƒç´ )', fontsize=18)
        ax1.set_title('çœ¼éœ‡å‡ç¼“åŒºåŸŸåˆ†è§£å›¾', fontsize=20, pad=20)
        ax1.legend(fontsize=16, loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = f'å¹³å‡å‡ç¼“æ•ˆç‡: {self.reduction_analysis["å¹³å‡å‡ç¼“æ•ˆç‡"]:.1f}%  |  '
        stats_text += f'å¹³å‡æ®‹ä½™çœ¼éœ‡: {self.reduction_analysis["å¹³å‡æ®‹ä½™çœ¼éœ‡"]:.1f}px  |  '
        stats_text += f'å¹³å‡å¼‚å¸¸å¢å¼º: {self.reduction_analysis["å¹³å‡å¼‚å¸¸å¢å¼º"]:.1f}px\n'
        stats_text += f'æ”¹å–„ç‡: {self.reduction_analysis["æ”¹å–„ç‡"]:.1f}%  |  '
        stats_text += f'æ¶åŒ–ç‡: {self.reduction_analysis["æ¶åŒ–ç‡"]:.1f}%  |  '
        stats_text += f'ä¿®æ­£NRMSE: {self.metrics["Xè½´NRMSE_ä¿®æ­£"]:.4f}'
        
        # æ·»åŠ è½¨è¿¹ç›¸å…³ä¿¡æ¯
        if self.trajectory_analysis.get('å¼ºåº¦ç­‰çº§'):
            stats_text += f'\nçœ¼éœ‡å¼ºåº¦: {self.trajectory_analysis["å¼ºåº¦ç­‰çº§"]} (è¯„åˆ†: {self.trajectory_analysis.get("å¼ºåº¦è¯„åˆ†", 0):.1f}/10)'
        
        ax1.text(0.02, 0.98, stats_text, transform=ax1.transAxes, 
                fontsize=13, verticalalignment='top',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
        
        # 2. Xè½´è¿åŠ¨è½¨è¿¹å¯¹æ¯”ï¼ˆä¿®æ­£ç‰ˆï¼‰
        ax2 = fig.add_subplot(gs[1, 0])
        
        # ç»˜åˆ¶çœŸå®è½¨è¿¹å’Œé¢„æµ‹è½¨è¿¹
        ax2.plot(self.data['frameId'], self.data['çœŸå®ä½ç§»_X'], 'r-', 
                linewidth=3, alpha=0.8, label='çœŸå®çœ¼éœ‡è½¨è¿¹')
        ax2.plot(self.data['frameId'], self.data['é¢„æµ‹ä½ç§»_X'], 'b-', 
                linewidth=3, alpha=0.8, label='UKFé¢„æµ‹è½¨è¿¹')
        
        # æ·»åŠ é›¶çº¿
        ax2.axhline(y=0, color='black', linestyle='-', linewidth=2, alpha=0.8)
        
        # å¡«å……å…¬å…±åŒºåŸŸï¼ˆå‡ç¼“åŒºåŸŸï¼‰
        for i in range(len(self.data)):
            frame_id = self.data.iloc[i]['frameId']
            real_pos = self.data.iloc[i]['çœŸå®ä½ç§»_X']
            pred_pos = self.data.iloc[i]['é¢„æµ‹ä½ç§»_X']
            
            # è®¡ç®—å…¬å…±åŒºåŸŸèŒƒå›´
            if real_pos >= 0 and pred_pos >= 0:  # éƒ½åœ¨æ­£å‘
                common_range = min(real_pos, pred_pos)
                ax2.fill_between([frame_id-0.5, frame_id+0.5], [0, 0], [common_range, common_range], 
                               alpha=0.3, color='green')
            elif real_pos <= 0 and pred_pos <= 0:  # éƒ½åœ¨è´Ÿå‘
                common_range = max(real_pos, pred_pos)
                ax2.fill_between([frame_id-0.5, frame_id+0.5], [0, 0], [common_range, common_range], 
                               alpha=0.3, color='green')
        
        ax2.set_xlabel('å¸§ID', fontsize=18)
        ax2.set_ylabel('ç›¸å¯¹ç¬¬ä¸€å¸§çš„Xä½ç§» (åƒç´ )', fontsize=18)
        ax2.set_title('Xè½´çœ¼éœ‡è½¨è¿¹å¯¹æ¯”ï¼ˆç»¿è‰²åŒºåŸŸä¸ºæœ‰æ•ˆå‡ç¼“åŒºåŸŸï¼‰', fontsize=20, pad=20)
        ax2.legend(fontsize=16)
        ax2.grid(True, alpha=0.3)
        ax2.tick_params(axis='both', which='major', labelsize=16)
        
        # æ·»åŠ è½¨è¿¹ç»Ÿè®¡ä¿¡æ¯
        trajectory_stats = f'çœŸå®è½¨è¿¹: æœ€å¤§ä½ç§»Â±{self.data["çœŸå®ä½ç§»_ç»å¯¹å€¼"].max():.1f}px, å¹³å‡{self.data["çœŸå®ä½ç§»_ç»å¯¹å€¼"].mean():.1f}px\n'
        trajectory_stats += f'é¢„æµ‹è½¨è¿¹: æœ€å¤§ä½ç§»Â±{self.data["é¢„æµ‹ä½ç§»_ç»å¯¹å€¼"].max():.1f}px, å¹³å‡{self.data["é¢„æµ‹ä½ç§»_ç»å¯¹å€¼"].mean():.1f}px\n'
        trajectory_stats += f'å…¬å…±åŒºåŸŸ: å¹³å‡{self.reduction_analysis["å¹³å‡å…¬å…±åŒºåŸŸ"]:.1f}px, æ®‹ä½™çœ¼éœ‡: å¹³å‡{self.reduction_analysis["å¹³å‡æ®‹ä½™çœ¼éœ‡"]:.1f}px'
        
        # æ·»åŠ è½¨è¿¹ç‰¹å¾ä¿¡æ¯
        if self.trajectory_analysis.get('æ³¢å½¢ç±»å‹'):
            trajectory_stats += f'\næ³¢å½¢ç±»å‹: {self.trajectory_analysis["æ³¢å½¢ç±»å‹"]}'
        if self.trajectory_analysis.get('æ–¹å‘æ¨¡å¼'):
            trajectory_stats += f', æ–¹å‘æ¨¡å¼: {self.trajectory_analysis["æ–¹å‘æ¨¡å¼"]}'
            
        ax2.text(0.02, 0.98, trajectory_stats, transform=ax2.transAxes, 
                fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))
        
        plt.tight_layout()
        plt.show()

    def create_page6_trajectory_summary(self):
        """ç¬¬6é¡µï¼šè½¨è¿¹ç‰¹å¾æ€»ç»“é¡µé¢ï¼ˆæ–°å¢ï¼‰"""
        fig = plt.figure(figsize=(24, 14))
        fig.suptitle('ğŸ“Š å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æ - ç¬¬6é¡µï¼šçœ¼éœ‡è½¨è¿¹ç‰¹å¾å…¨é¢æ€»ç»“', fontsize=24, y=0.96)
        
        gs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.25)
        
        # 1. çœ¼éœ‡ç‰¹å¾é›·è¾¾å›¾
        ax1 = fig.add_subplot(gs[0, 0], projection='polar')
        
        # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        categories = ['å¼ºåº¦è¯„åˆ†', 'é¢‘ç‡ç¨³å®šæ€§', 'æ³¢å½¢å¯¹ç§°æ€§', 'æ³¢å½¢å‘¨æœŸæ€§', 
                     'æ–¹å‘æŒç»­æ€§', 'è¿åŠ¨è¿ç»­æ€§', 'ä¿¡å·å¤æ‚æ€§']
        
        values = [
            self.trajectory_analysis.get('å¼ºåº¦è¯„åˆ†', 0) / 10,  # å½’ä¸€åŒ–åˆ°0-1
            self.trajectory_analysis.get('é¢‘ç‡ç¨³å®šæ€§', 0),
            self.trajectory_analysis.get('æ³¢å½¢å¯¹ç§°æ€§', 0),
            self.trajectory_analysis.get('æ³¢å½¢å‘¨æœŸæ€§', 0),
            self.trajectory_analysis.get('æ–¹å‘æŒç»­æ€§', 0),
            self.trajectory_analysis.get('è¿åŠ¨è¿ç»­æ€§', 0),
            min(1, self.trajectory_analysis.get('ä¿¡å·å¤æ‚æ€§', 0))  # é™åˆ¶åœ¨0-1èŒƒå›´
        ]
        
        # è¡¥å…¨é›·è¾¾å›¾ï¼ˆé—­åˆï¼‰
        values += values[:1]
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]
        
        # ç»˜åˆ¶é›·è¾¾å›¾
        ax1.plot(angles, values, 'o-', linewidth=3, color='blue', alpha=0.7)
        ax1.fill(angles, values, alpha=0.25, color='blue')
        
        # è®¾ç½®æ ‡ç­¾
        ax1.set_xticks(angles[:-1])
        ax1.set_xticklabels(categories, fontsize=12)
        ax1.set_ylim(0, 1)
        ax1.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax1.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)
        ax1.set_title('çœ¼éœ‡ç‰¹å¾é›·è¾¾å›¾', fontsize=16, pad=20)
        ax1.grid(True)
        
        # 2. é¢‘ç‡åˆ†å¸ƒé¥¼å›¾
        ax2 = fig.add_subplot(gs[0, 1])
        
        if self.trajectory_analysis.get('é¢‘å¸¦åˆ†å¸ƒ'):
            # ä½¿ç”¨è®¡ç®—å‡ºçš„é¢‘å¸¦åˆ†å¸ƒ
            band_data = self.trajectory_analysis['é¢‘å¸¦åˆ†å¸ƒ']
            # åªæ˜¾ç¤ºå æ¯”è¶…è¿‡5%çš„é¢‘å¸¦
            significant_bands = {k: v for k, v in band_data.items() if v > 5}
            
            if significant_bands:
                labels = list(significant_bands.keys())
                sizes = list(significant_bands.values())
                colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc']
                
                wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors[:len(labels)], 
                                                   autopct='%1.1f%%', startangle=90)
                
                for text in texts:
                    text.set_fontsize(11)
                for autotext in autotexts:
                    autotext.set_fontsize(10)
                    autotext.set_color('white')
                    autotext.set_weight('bold')
        else:
            # å¦‚æœæ²¡æœ‰é¢‘å¸¦åˆ†å¸ƒæ•°æ®ï¼Œæ˜¾ç¤ºä¸»é¢‘ç‡ä¿¡æ¯
            ax2.text(0.5, 0.5, f'ä¸»é¢‘ç‡\n{self.trajectory_analysis.get("ä¸»é¢‘ç‡", 0):.2f} Hz\n\n{self.trajectory_analysis.get("é¢‘ç‡åˆ†ç±»", "æœªçŸ¥")}', 
                    ha='center', va='center', fontsize=16, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        
        ax2.set_title('é¢‘å¸¦èƒ½é‡åˆ†å¸ƒ', fontsize=16, pad=20)
        
        # 3. æ–¹å‘æ€§åˆ†ææŸ±çŠ¶å›¾
        ax3 = fig.add_subplot(gs[1, 0])
        
        direction_data = [
            self.trajectory_analysis.get('å³å‘è¿åŠ¨æ¯”ä¾‹', 0) * 100,
            self.trajectory_analysis.get('å·¦å‘è¿åŠ¨æ¯”ä¾‹', 0) * 100,
            self.trajectory_analysis.get('é™æ­¢æ¯”ä¾‹', 0) * 100
        ]
        direction_labels = ['å³å‘è¿åŠ¨', 'å·¦å‘è¿åŠ¨', 'ç›¸å¯¹é™æ­¢']
        colors = ['red', 'blue', 'gray']
        
        bars = ax3.bar(direction_labels, direction_data, color=colors, alpha=0.7)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, direction_data):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{value:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        ax3.set_ylabel('æ—¶é—´æ¯”ä¾‹ (%)', fontsize=14)
        ax3.set_title('è¿åŠ¨æ–¹å‘åˆ†å¸ƒ', fontsize=16, pad=20)
        ax3.set_ylim(0, max(direction_data) * 1.2)
        ax3.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ–¹å‘æ¨¡å¼ä¿¡æ¯
        direction_pattern = self.trajectory_analysis.get('æ–¹å‘æ¨¡å¼', 'æœªçŸ¥')
        ax3.text(0.5, 0.95, f'æ–¹å‘æ¨¡å¼: {direction_pattern}', 
                transform=ax3.transAxes, ha='center', va='top',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"),
                fontsize=12, fontweight='bold')
        
        # 4. ç»¼åˆè¯„ä¼°æ–‡æœ¬æ€»ç»“
        ax4 = fig.add_subplot(gs[1, 1])
        ax4.axis('off')  # éšè—åæ ‡è½´
        
        # æ„å»ºç»¼åˆè¯„ä¼°æ–‡æœ¬
        summary_text = "ğŸ¥ çœ¼éœ‡è½¨è¿¹ç»¼åˆè¯„ä¼°æŠ¥å‘Š\n"
        summary_text += "=" * 35 + "\n\n"
        
        # åŸºæœ¬åˆ†ç±»
        nystagmus_types = self.trajectory_analysis.get('çœ¼éœ‡ç±»å‹', ['æœªçŸ¥'])
        summary_text += f"ğŸ“Š çœ¼éœ‡åˆ†ç±»: {', '.join(nystagmus_types)}\n"
        summary_text += f"ğŸ¯ è¿åŠ¨æ¨¡å¼: {self.trajectory_analysis.get('çœ¼éœ‡æ¨¡å¼', 'æœªçŸ¥')}\n"
        summary_text += f"ğŸ’ª å¼ºåº¦ç­‰çº§: {self.trajectory_analysis.get('å¼ºåº¦ç­‰çº§', 'æœªçŸ¥')}\n"
        summary_text += f"    è¯„åˆ†: {self.trajectory_analysis.get('å¼ºåº¦è¯„åˆ†', 0):.1f}/10\n\n"
        
        # é¢‘ç‡ç‰¹å¾
        if self.trajectory_analysis.get('ä¸»é¢‘ç‡', 0) > 0:
            summary_text += f"ğŸ“¡ ä¸»é¢‘ç‡: {self.trajectory_analysis['ä¸»é¢‘ç‡']:.2f} Hz\n"
            summary_text += f"ğŸ“ˆ é¢‘ç‡åˆ†ç±»: {self.trajectory_analysis.get('é¢‘ç‡åˆ†ç±»', 'æœªçŸ¥')}\n"
            summary_text += f"ğŸ¯ é¢‘ç‡ç¨³å®šæ€§: {self.trajectory_analysis.get('é¢‘ç‡ç¨³å®šæ€§', 0):.2f}\n\n"
        else:
            summary_text += f"ğŸ“¡ é¢‘ç‡ç‰¹å¾: æ— æ˜æ˜¾å‘¨æœŸæ€§\n\n"
        
        # æ³¢å½¢ç‰¹å¾
        summary_text += f"ğŸŒŠ æ³¢å½¢ç‰¹å¾:\n"
        summary_text += f"    ç±»å‹: {self.trajectory_analysis.get('æ³¢å½¢ç±»å‹', 'æœªçŸ¥')}\n"
        summary_text += f"    å¯¹ç§°æ€§: {self.trajectory_analysis.get('æ³¢å½¢å¯¹ç§°æ€§', 0):.2f}\n"
        summary_text += f"    å‘¨æœŸæ€§: {self.trajectory_analysis.get('æ³¢å½¢å‘¨æœŸæ€§', 0):.2f}\n\n"
        
        # æ–¹å‘æ€§ç‰¹å¾
        summary_text += f"ğŸ§­ æ–¹å‘æ€§ç‰¹å¾:\n"
        summary_text += f"    æ¨¡å¼: {self.trajectory_analysis.get('æ–¹å‘æ¨¡å¼', 'æœªçŸ¥')}\n"
        summary_text += f"    æŒç»­æ€§: {self.trajectory_analysis.get('æ–¹å‘æŒç»­æ€§', 0):.2f}\n"
        summary_text += f"    åå‘æ€§: {self.trajectory_analysis.get('æ–¹å‘åå‘æ€§', 0):.2f}\n\n"
        
        # è¿åŠ¨è´¨é‡
        summary_text += f"âš¡ è¿åŠ¨è´¨é‡:\n"
        summary_text += f"    è¿ç»­æ€§: {self.trajectory_analysis.get('è¿åŠ¨è¿ç»­æ€§', 0)*100:.1f}%\n"
        summary_text += f"    å¤æ‚æ€§: {self.trajectory_analysis.get('ä¿¡å·å¤æ‚æ€§', 0):.3f}\n"
        summary_text += f"    å¹³å‡é€Ÿåº¦: {self.trajectory_analysis.get('å¹³å‡é€Ÿåº¦', 0):.1f} px/s\n\n"
        
        # ä¸´åºŠå»ºè®®
        summary_text += f"ğŸ¥ ä¸´åºŠå»ºè®®:\n"
        
        # æ ¹æ®åˆ†æç»“æœç»™å‡ºå»ºè®®
        intensity_score = self.trajectory_analysis.get('å¼ºåº¦è¯„åˆ†', 0)
        main_freq = self.trajectory_analysis.get('ä¸»é¢‘ç‡', 0)
        
        if intensity_score >= 7:
            summary_text += f"âš ï¸  é«˜å¼ºåº¦çœ¼éœ‡ï¼Œå»ºè®®è¯¦ç»†æ£€æŸ¥\n"
        elif intensity_score >= 4:
            summary_text += f"ğŸ“‹ ä¸­ç­‰å¼ºåº¦ï¼Œå»ºè®®å®šæœŸè§‚å¯Ÿ\n"
        else:
            summary_text += f"âœ… è½»åº¦çœ¼éœ‡ï¼Œç»§ç»­ç›‘æµ‹\n"
        
        if 1 <= main_freq <= 5:
            summary_text += f"ğŸ“ˆ é¢‘ç‡æ­£å¸¸èŒƒå›´\n"
        elif main_freq > 8:
            summary_text += f"âš ï¸  é«˜é¢‘ç‰¹å¾ï¼Œéœ€è¿›ä¸€æ­¥è¯„ä¼°\n"
        
        # æ˜¾ç¤ºæ–‡æœ¬
        ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, 
                fontsize=11, verticalalignment='top', horizontalalignment='left',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8),
                family='monospace')
        
        plt.tight_layout()
        plt.show()

    def run_enhanced_analysis_with_trajectory(self):
        """è¿è¡ŒåŒ…å«æ·±åº¦è½¨è¿¹åˆ†æçš„å®Œæ•´Xè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†ææµç¨‹"""
        if self.data is None:
            return
        
        print("\n" + "="*90)
        print("ğŸš€ å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æç³»ç»Ÿ v4.0ï¼ˆå«æ·±åº¦è½¨è¿¹ç‰¹æ€§åˆ†æï¼‰")
        print("="*90)
        
        # å¯ç”¨matplotlibçš„äº¤äº’æ¨¡å¼
        plt.ion()
        
        # 1. æ·±åº¦çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æï¼ˆæ–°å¢ï¼‰
        self.analyze_nystagmus_trajectory_characteristics()
        
        # 2. è®¡ç®—è¯¯å·®
        self.calculate_errors()
        
        # 3. è®¡ç®—å‡†ç¡®æ€§æŒ‡æ ‡
        self.calculate_accuracy_metrics()
        
        # 4. åˆ†æçœ¼éœ‡å‡ç¼“æ•ˆæœï¼ˆä¿®æ­£ç‰ˆï¼‰
        self.analyze_nystagmus_reduction()
        
        # 5. æ‰“å°è½¨è¿¹åˆ†ææŠ¥å‘Š
        self.print_comprehensive_trajectory_report()
        
        # 6. æ‰“å°UKFé¢„æµ‹åˆ†ææŠ¥å‘Š
        self.print_analysis_report()
        
        # 7. åˆ›å»º6é¡µå¯è§†åŒ–åˆ†æ
        print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆ6é¡µå¢å¼ºç‰ˆXè½´ä¸“ç”¨å¯è§†åŒ–åˆ†æ...")
        print("   ğŸ–±ï¸ æ‰€æœ‰å›¾è¡¨æ”¯æŒé¼ æ ‡æ»šè½®ç¼©æ”¾å’Œæ‹–åŠ¨å¹³ç§»")
        print("   âœ¨ æ–°å¢ï¼šæ·±åº¦çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æ")
        print("   ğŸ”¬ æ–°å¢ï¼šçœ¼éœ‡ç±»å‹ã€æ¨¡å¼ã€é¢‘ç‡ã€æ³¢å½¢ã€æ–¹å‘æ€§å…¨é¢åˆ†æ")
        print("   ğŸ“ˆ æ–°å¢ï¼šä¸´åºŠæ„ä¹‰è¯„ä¼°")
        
        print("   ç¬¬1é¡µï¼šXè½´è·Ÿè¸ªæ•ˆæœä¸è¯¯å·®åˆ†æï¼ˆå«è½¨è¿¹ä¿¡æ¯ï¼‰")
        self.create_page1_tracking_and_error()
        
        print("   ç¬¬2é¡µï¼šXè½´ç²¾åº¦åˆ†æï¼ˆå«è½¨è¿¹ç‰¹å¾ï¼‰")
        self.create_page2_precision_analysis()
        
        print("   ç¬¬3é¡µï¼šæ·±åº¦çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æï¼ˆåŠ¨åŠ›å­¦+é¢‘è°±+æ³¢å½¢ï¼‰")
        self.create_page3_enhanced_nystagmus_analysis()
        
        print("   ç¬¬4é¡µï¼šç›¸å…³æ€§ä¸æ–¹å‘æ€§åˆ†æï¼ˆæ•£ç‚¹+æ–¹å‘æ€§ï¼‰")
        self.create_page4_scatter_analysis()
        
        print("   ç¬¬5é¡µï¼šçœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æï¼ˆä¿®æ­£ç‰ˆ+è½¨è¿¹ç‰¹å¾ï¼‰")
        self.create_page5_corrected_reduction_analysis()
        
        print("   ç¬¬6é¡µï¼šçœ¼éœ‡è½¨è¿¹ç‰¹å¾å…¨é¢æ€»ç»“ï¼ˆé›·è¾¾å›¾+ç»¼åˆè¯„ä¼°ï¼‰")
        self.create_page6_trajectory_summary()
        
        print("\n" + "="*90)
        print("âœ… å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹åˆ†æå®Œæˆï¼")
        print("   ğŸ¯ ä¸“æ³¨äºXè½´æ•°æ®æ·±åº¦åˆ†æ")
        print("   ğŸ“Š 6é¡µä¸“ä¸šå¯è§†åŒ–å±•ç¤º")
        print("   ğŸ”¬ å…¨é¢çš„çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æï¼š")
        print("      â€¢ çœ¼éœ‡ç±»å‹è¯†åˆ«ï¼ˆå¹…åº¦ã€é€Ÿåº¦ã€è§„å¾‹æ€§åˆ†ç±»ï¼‰")
        print("      â€¢ çœ¼éœ‡æ¨¡å¼è¯†åˆ«ï¼ˆæ‘†åŠ¨æ€§ã€å†²åŠ¨æ€§ã€æ··åˆæ€§ï¼‰")
        print("      â€¢ å¢å¼ºç‰ˆé¢‘ç‡åˆ†æï¼ˆä¸»é¢‘ç‡ã€è°æ³¢ã€é¢‘å¸¦åˆ†å¸ƒï¼‰")
        print("      â€¢ çœ¼éœ‡å¼ºåº¦è¯„ä¼°ï¼ˆå¤šç»´åº¦å¼ºåº¦æŒ‡æ ‡ï¼‰")
        print("      â€¢ æ³¢å½¢ç‰¹å¾åˆ†æï¼ˆå¯¹ç§°æ€§ã€å¹³æ»‘åº¦ã€å‘¨æœŸæ€§ï¼‰")
        print("      â€¢ æ–¹å‘æ€§åˆ†æï¼ˆæ–¹å‘åå¥½ã€æŒç»­æ€§ã€è¿åŠ¨èŒƒå›´ï¼‰")
        print("   ğŸ“ˆ å…¨é¢çš„UKFé¢„æµ‹ç²¾åº¦è¯„ä¼°ï¼ˆå«NRMSEï¼‰")
        print("   ğŸ¯ ä¿®æ­£ç‰ˆçœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æ")
        print("   ğŸ¥ ä¸´åºŠæ„ä¹‰è¯„ä¼°å’Œå»ºè®®")
        print("   ğŸ“‹ ç»¼åˆè½¨è¿¹ç‰¹å¾æ€»ç»“æŠ¥å‘Š")
        print("="*90)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ‘ï¸ å¢å¼ºç‰ˆXè½´çœ¼éœ‡UKFé¢„æµ‹å‡†ç¡®æ€§åˆ†æå·¥å…· v4.0ï¼ˆå«æ·±åº¦è½¨è¿¹åˆ†æï¼‰")
    print("="*90)
    print("âœ¨ æ–°å¢ç‰¹æ€§:")
    print("   ğŸ”¬ æ·±åº¦çœ¼éœ‡è½¨è¿¹ç‰¹æ€§åˆ†æ")
    print("   ğŸ“Š çœ¼éœ‡ç±»å‹è‡ªåŠ¨è¯†åˆ«ï¼ˆå¹…åº¦/é€Ÿåº¦/è§„å¾‹æ€§åˆ†ç±»ï¼‰")
    print("   ğŸŒŠ çœ¼éœ‡æ¨¡å¼è¯†åˆ«ï¼ˆæ‘†åŠ¨æ€§/å†²åŠ¨æ€§/æ··åˆæ€§/æ¼‚ç§»æ€§ï¼‰")
    print("   ğŸ“¡ å¢å¼ºç‰ˆé¢‘ç‡åˆ†æï¼ˆä¸»é¢‘ç‡/è°æ³¢/é¢‘å¸¦åˆ†å¸ƒ/ç¨³å®šæ€§ï¼‰")
    print("   ğŸ’ª å¤šç»´åº¦å¼ºåº¦è¯„ä¼°ï¼ˆä½ç§»/é€Ÿåº¦/åŠ é€Ÿåº¦/å¤æ‚æ€§/è¿ç»­æ€§ï¼‰")
    print("   ğŸŒŠ æ³¢å½¢ç‰¹å¾åˆ†æï¼ˆå¯¹ç§°æ€§/å¹³æ»‘åº¦/å‘¨æœŸæ€§/ç±»å‹åˆ†ç±»ï¼‰")
    print("   ğŸ§­ æ–¹å‘æ€§ç‰¹å¾åˆ†æï¼ˆæ–¹å‘åå¥½/æŒç»­æ€§/è¿åŠ¨èŒƒå›´ï¼‰")
    print("   ğŸ¥ ä¸´åºŠæ„ä¹‰è¯„ä¼°å’Œå»ºè®®")
    print("   ğŸ“‹ 6é¡µä¸“ä¸šå¯è§†åŒ–ï¼ˆæ–°å¢è½¨è¿¹ç‰¹å¾æ€»ç»“é¡µï¼‰")
    print("   ğŸ¯ é›·è¾¾å›¾å±•ç¤ºçœ¼éœ‡ç‰¹å¾å…¨è²Œ")
    print("   ğŸ“ˆ ç»¼åˆè½¨è¿¹ç‰¹å¾æŠ¥å‘Š")
    print("="*90)
    print("ğŸ’¡ ä¿ç•™åŸæœ‰åŠŸèƒ½:")
    print("   ğŸ¯ UKFé¢„æµ‹å‡†ç¡®æ€§åˆ†æ")
    print("   ğŸ“Š NRMSEï¼ˆå½’ä¸€åŒ–RMSEï¼‰åˆ†æ")
    print("   ğŸ”„ ä¿®æ­£ç‰ˆçœ¼éœ‡å‡ç¼“æ•ˆæœåˆ†æ")
    print("   ğŸ–±ï¸ æ‰€æœ‰å›¾è¡¨æ”¯æŒé¼ æ ‡äº¤äº’")
    print("="*90)
    
    # åˆ›å»ºå¢å¼ºç‰ˆXè½´åˆ†æå™¨
    analyzer = EnhancedXAxisNystagmusAnalyzer('prediction_only_data.csv', fps=60)
    
    # è¿è¡ŒåŒ…å«æ·±åº¦è½¨è¿¹åˆ†æçš„å®Œæ•´åˆ†æ
    if analyzer.data is not None:
        analyzer.run_enhanced_analysis_with_trajectory()
    else:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        print("   ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—: frameId, actualX, predictedX")
    
    # ä¿æŒå›¾å½¢çª—å£æ‰“å¼€
    input("\næŒ‰å›è½¦é”®é€€å‡º...")
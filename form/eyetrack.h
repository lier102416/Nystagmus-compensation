#ifndef EYETRACK_H
#define EYETRACK_H

#include <QWidget>
#include <opencv2/opencv.hpp>
#include <QTimer>
#include "class.h"
#include <QCameraDevice>
#include <QMediaDevices>
#include "qcustomplot.h"
#include <pipline.h>
#include "videocapturepip.h"
#include "rolextractionpip.h"
#include "pupilextractionpip.h"
#include "spotextractionpip.h"
#include "gazeukf.h"
#include <QTextEdit>
#include "datesave.h"
#include "improvegazeukf.h"
#include "nystagmuadaptiveukf.h"
#include "nystagmusphasedetector.h"
#include "improvenystagmusphashdetector.h"
#include "nystagmusanalyzer.h"
#include "enhancenystagmusphasedetector.h"
#include "smart_frame_jump_handler.h"
#include "enhanced_naystagmus_prediction_optimizer.h"
#include "adaptiveparametercontroller.h"
#include "conservativenystagmuspredictor.h"
#include "advancedoutliercontroller.h"
#include "enhancedpredictor.h"
#include "temporalconsistencyfilter.h"
#include "enhancedoutliercontroller.h"
#include "mergedprocessingpip.h"
#include "class.h"
#include "improvednystagmuspredictor.h"
#include "enhancednystagmuspredictor.h"
#include "tunednystagmuspredictor.h"
#include "AntiOvershootNystagmusPredictor.h"
#include "finetunednystagmuspredictor.h"
#include "optimizedtunednystagmuspredictor.h"
#include "simplifiedoptimizedpredictor.h"
#include "horizontalnystagmuspredictor.h"
#include "purexaxispredictor.h"
#include "purexaxisukfpredictor.h"
#include "FinalPureXAxisUKFPredictor.h"
#include "RobustPureXAxisUKFPredictor.h"
#include "balancedpurexaxisukfpredictor.h"
#include "improvedbalancedpurexaxisukfpredictor.h"
#include "stableukfpredictor.h"
#include "lowlatencyukfpredictor.h"
#include "asymmetricnystagmuspredictor.h"
#include "optimizednystagmuspredictor.h"
#include "nystagmusawarepredictor.h"
#include "aggressivenystagmuspredictor.h"

#include "nystagmusoptimizedpredictor.h"
#include "simplestablenystagmuspredictor.h"
#include "zerolagpredictor.h"
#include "balancedlowlatencypredictor.h"
#include "nystagmuspeakawarepredictor.h"
#include "simplepeakoptimizer.h"

#include "improvednystagmuspeakdetector.h"
#include "PredictorComparison.h"
#include "enhancedarxpredictor.h"

#include "SingleAlphaBetaGammaPredictor.h"
#include "ARXPredictor.h"
#include "kalmanfilterpredictor.h"
#include "optimizedpurexaxisukfpredictor.h"

#include "L2L3Predictor.h"
#include "L1L2Predictor.h"
#include "L1OnlyPredictor.h"

namespace Ui {
class eyeTrack;
}

enum SystemState {
    STOPPED,
    STARTING,
    RUNNING,
    STOPPING
};


struct VarianceMetrics {
    double varianceX = 0.0;
    double varianceY = 0.0;
    double totalVariance = 0.0;
    double meanError = 0.0;
    double accuracy = 0.0;
};



class eyeTrack : public QWidget
{
    Q_OBJECT

private:
    //å³°å€¼æ£€æµ‹
    struct PeakDetectionInfo {
        int lastPeakFrame = -1;
        cv::Point2f lastPeakPosition;
        cv::Point2f lastPeakDirection;
        float lastPeakVelocity = 0;
        int totalPeaksDetected = 0;
        int compensationFrameCount = 2;
        cv::Point2f baseCompensationError;
        // æ–°å¢ï¼šè¡¥å¿ç›¸å…³
        bool compensationActive = false;
        bool skipNextCompensation = false;  //è·³è¿‡ä¸‹ä¸€æ¬¡è¡¥å¿æ ‡å¿—
        int compensationStartFrame = -1;
    } peakInfo;

    // æ¨¡æ‹Ÿç»Ÿè®¡
    struct NystagmusSimStats {
        int totalFrames = 0;
        double maxOffset = 0.0;
        double avgOffset = 0.0;
        double totalOffset = 0.0;
        std::deque<cv::Point2f> recentOffsets;
        std::deque<double> offsetMagnitudes;

        void updateStats(const cv::Point2f& offset) {
            totalFrames++;
            double magnitude = cv::norm(offset);

            maxOffset = std::max(maxOffset, magnitude);
            totalOffset += magnitude;
            avgOffset = totalOffset / totalFrames;

            recentOffsets.push_back(offset);
            offsetMagnitudes.push_back(magnitude);

            // ä¿æŒæœ€è¿‘100å¸§çš„æ•°æ®
            if (recentOffsets.size() > 100) {
                recentOffsets.pop_front();
                offsetMagnitudes.pop_front();
            }
        }

        void reset() {
            totalFrames = 0;
            maxOffset = 0.0;
            avgOffset = 0.0;
            totalOffset = 0.0;
            recentOffsets.clear();
            offsetMagnitudes.clear();
        }
    } simStats;

    struct CorrectionParams {
        double gainFactor = 1.0;     // çŸ«æ­£å¢ç›Š
        double maxOffset = 50.0;     // æœ€å¤§åç§»é™åˆ¶
        bool enableCorrection = true; // å¯ç”¨çŸ«æ­£
        double deadZone = 2.0;       // æ­»åŒºï¼Œå°äºæ­¤å€¼çš„åç§»å°†è¢«å¿½ç•¥
    } correctionParams;
    cv::Mat fieldImage;           //è§†é‡å›¾åƒ


    // æ€§èƒ½ç»Ÿè®¡ï¼ˆå®Œå…¨ä»å¹¶è¡Œç‰ˆæœ¬å¤åˆ¶ï¼‰
    static struct PerformanceStats {
        int totalFrames = 0;
        int highPrecisionFrames = 0;  // <5åƒç´ è¯¯å·®
        int frameJumps = 0;
        std::deque<double> recentErrors;
        const int ERROR_WINDOW = 100;  // ğŸ”§ å…³é”®ï¼šæ”¹ä¸ºå’Œå¹¶è¡Œç‰ˆæœ¬ä¸€è‡´çš„100
        double horizontalErrorSum = 0;
        double verticalErrorSum = 0;
        std::chrono::high_resolution_clock::time_point lastReportTime;

        PerformanceStats() {
            lastReportTime = std::chrono::high_resolution_clock::now();
        }

        double getRecentAvgError() const {
            if (recentErrors.empty()) return 0;
            return std::accumulate(recentErrors.begin(), recentErrors.end(), 0.0) / recentErrors.size();
        }
    } performanceStats;

    // æ•°æ®éªŒè¯æ ‡å¿—
    struct ValidationResult {
        bool success = false;
        bool hasFrameData = false;
        bool imageValid = false;
        bool gazeValid = false;
        bool lightPointsValid = false;
        bool pupilValid = false;
        std::string failReason;
    };


    Ui::eyeTrack * ui;
    QTimer * timer;
    QList<QCameraDevice> cameras;// æ‘„åƒå¤´åˆ—è¡¨
    std::vector<MappingCoefficients> m_mappingCoefficients;//æ˜ å°„å‡½æ•°ç³»æ•°
    MappingCoefficients combinedMappingCoefficients;//æ˜ å°„å‡½æ•°ç³»æ•°

    QLabel* performanceLabel;

    dateSave imageSave;
    QPushButton* m_stopButton;  //æš‚åœ
    QPushButton* m_starButton;  //å¼€å§‹æŒ‰é’®


    //åŸå§‹æ³¨è§†ç‚¹
    QCustomPlot * GazePlot;
    QCPGraph *GazePointGraph;
    QVector<double> GazeX, GazeY;

    //é¢„æµ‹æ³¨è§†ç‚¹
    QCustomPlot * PredictPlot;
    QCPGraph *PredictPointGraph;
    QVector<double> PredictX, PredictY;

    MergedProcessingPip * mergedPip;
    //å›¾åƒå¤„ç†ç®¡çº¿
    pipline *pip;
    videoCapturePip* cameraPipe;  // ä¿ç•™è§†é¢‘é‡‡é›†

    SystemState currentState = STOPPED;  // æ˜ç¡®åˆå§‹çŠ¶æ€

    bool cameraFlag = false;
    bool hasValidData;

    int xPos = 0;
    int yPos = 0;
    QElapsedTimer QEtimer;//æ—¶é—´æ£€æµ‹

    //é¢„æµ‹ç³»ç»Ÿ - åœ¨eyetrackä¸­åˆå§‹åŒ–ï¼Œä½†å®é™…é¢„æµ‹é€»è¾‘åœ¨processMergedResultä¸­ä½¿ç”¨é™æ€å˜é‡
    BalancedLowLatencyPredictor    predictionSystem;  // ä½¿ç”¨ç¨³å¥ç‰ˆé¢„æµ‹å™¨

    SingleAlphaBetaGammaPredictor alphaBetaPredictor;  // Add this
    ARXPredictor arxPredictor;  // Add this

    OptimizedPureXAxisUKFPredictor kalmanPredictor;  // æ·»åŠ å¡å°”æ›¼æ»¤æ³¢é¢„æµ‹å™¨

    L2L3Predictor l2l3Predictor;      // L2+L3 (æ— è‡ªé€‚åº”å‰ç»)
    L1L2Predictor l1l2Predictor;      // L1+L2 (æ— è¶‹åŠ¿å¢å¼º)
    L1OnlyPredictor l1OnlyPredictor;  // ä»…L1 (è‡ªé€‚åº”å‰ç»)

    // å­˜å‚¨å„é¢„æµ‹å™¨çš„Xè½´é¢„æµ‹å€¼ç”¨äºå¯¹æ¯”
    std::map<int, float> m_l2l3PredictionsX;
    std::map<int, float> m_l1l2PredictionsX;
    std::map<int, float> m_l1OnlyPredictionsX;

    std::map<int, float> m_kalmanPredictionsX;  // å­˜å‚¨å¡å°”æ›¼é¢„æµ‹çš„Xè½´å€¼

    std::map<int, float> m_balancedPredictionsX;
    std::map<int, float> m_alphaBetaPredictionsX;
    std::map<int, float> m_arxPredictionsX;
    std::map<int, float> m_actualGazeX;



    // æ·»åŠ ç”¨äºå›¾åƒçŸ«æ­£çš„æˆå‘˜å˜é‡
    cv::Mat baseImage;           // åŸºå‡†å›¾åƒ
    cv::Point2f currentOffset;   // å½“å‰åç§»é‡
    cv::Point2f smoothOffset;    // å¹³æ»‘åçš„åç§»é‡
    double smoothingFactor = 0.3; // å¹³æ»‘ç³»æ•°


    // çœ¼éœ‡æ¨¡æ‹Ÿç›¸å…³æˆå‘˜
    bool nystagmusSimulationActive = false; //false ä¸ºçœŸå®çœ¼éœ‡ true ä¸ºçŸ«æ­£å
    QTimer* simulationTimer = nullptr;
    cv::Mat originalFieldImage;  // ä¿å­˜åŸå§‹èƒŒæ™¯å›¾åƒ
    cv::Point2f lastGazePoint;   // ä¸Šä¸€ä¸ªæ³¨è§†ç‚¹ï¼Œç”¨äºè®¡ç®—åç§»
    cv::Point2f centerReference; // ä¸­å¿ƒå‚è€ƒç‚¹
    bool hasGazeReference = false;


    // å›ºå®šå›¾åƒä¸­å¿ƒå‚è€ƒç‚¹
    cv::Point2f imageCenterReference;      // å›¾åƒä¸­å¿ƒä½œä¸ºå›ºå®šå‚è€ƒç‚¹
    cv::Size imageSize;                    // å›¾åƒå°ºå¯¸

    // æ¨¡å¼çŠ¶æ€
    enum CorrectionMode {
        MODE_NORMAL_CORRECTION,
        MODE_NYSTAGMUS_SIMULATION
    } currentCorrectionMode;

    // å¸¸é‡å®šä¹‰
    static const int IMAGE_WIDTH = 1920;
    static const int IMAGE_HEIGHT = 1080;


public:
    explicit eyeTrack(QWidget *parent = nullptr);
    ~eyeTrack();
    cv::Mat image;
    bool flat = true;
    int moveSpeed = 5;  // ç§»åŠ¨é€Ÿåº¦
    int stripeWidth = 30;  // æ¡çº¹å®½åº¦
    bool horizontalMovement = true;
    bool detectionFlag = 0;
    int labelWidth = 1000;
    int labelHight = 600;
    int dataFlag = 1;

    std::map<int, cv::Point2f> m_actualPredictions;     // å­˜å‚¨çœŸæ­£çš„é¢„æµ‹å€¼ï¼ˆä¹‹å‰å¯¹è¯¥å¸§çš„é¢„æµ‹ï¼‰

    std::map<int, cv::Point2f> m_nextFramePredictions;  // å­˜å‚¨å¯¹ä¸‹ä¸€å¸§çš„é¢„æµ‹
    std::map<int , cv::Point2f> m_trueGazePoints;       // å­˜å‚¨çœŸå®çœ¼éœ‡


    std::map<int , std::vector<cv::Point2f>> lightTotal;
    std::map<int , cv::Point2f> pupilTotal;
    std::map<int , float> eccentricityTotal;
    std::map<int , float> circularityTotal;

    std::map<int , float> angelTotal;
    std::map<int , float> areaTotal;


    std::map<int , double> videoCaptureTime;
    std::map<int , double> pupilTime;
    std::map<int , double> roiTime;
    std::map<int , double> spotTime;
    std::map<int , double> predictTime;
    std::map<int , double> DrawTime;

    std::vector<float> m_predictionErrors;

    cv::Point2f lastPrediction ;
    bool first = 0;
    int pCount = 0; //é¢„æµ‹è®¡æ•°

    mutable QMutex m_dataStorageMutex;

    // æ·»åŠ å¸§å¤„ç†è®°å½•ï¼Œé˜²æ­¢é‡å¤å¤„ç†
    QSet<int> m_processedFrameIds;
    mutable QMutex m_processedFrameMutex;

    cv::Point2f lastValidMeasurement;
    bool hasLastMeasurement = false;


    void processVideoFrame(int frameId);
    void scanCreamDevice();



    void acceptanceCoefficient(const std::vector<MappingCoefficients> & coefficients, const MappingCoefficients & coefficient);

    void SaveCollectingData();

    void drawMarkersAndDisplay(cv::Mat& image, const FrameData& frameData, int frameId);
    void displayImage(const cv::Mat& image);
    void displayImageOnly(const cv::Mat& image);

    void initializeComponents();
    void drawFrameDataAndDisplay(cv::Mat& image, const FrameData& frameData,
                                 const cv::Point2f& gazePoint, const cv::Point2f& predictedGaze) ;
    void outputPerformanceReport(int frameId);
    void updateGazePlots(const cv::Point2f& gazePoint, const cv::Point2f& prediction, int frameId);
    void saveInvalidFrameImage(const cv::Mat& image, int frameId, QString fileName);

    void processMergedResult(int frameId, bool success);

    void drawPartialFrameData(cv::Mat& image, const FrameData& frameData, int frameId);

    void drawParallelMarkersAndDisplay(cv::Mat& rgbImage, FrameData *frameData, int frameId);

    bool isSystemRunning() const;
    bool isSystemReady() const;

    // è®¡ç®—ä½ç§»å·®å¼‚çš„å‡½æ•°
    cv::Point2f calculateDisplacement(const cv::Point2f& gazePoint, const cv::Point2f& predictedPoint);
    // åº”ç”¨éœ‡é¢¤çŸ«æ­£
    void applyTremorCorrection(const cv::Point2f& displacement);
    // æ›´æ–°çŸ«æ­£åçš„å›¾åƒæ˜¾ç¤º
    void updateCorrectedImageDisplay();
    // åº”ç”¨ç©ºé—´çŸ«æ­£
    void applySpatialCorrection(const cv::Mat& inputImage, cv::Mat& outputImage, const cv::Point2f& offset);
    // å¤„ç†è¾¹ç•Œæ•ˆåº”
    void handleBoundaryEffects(cv::Mat& image, const cv::Point2f& offset);

    void addCorrectionOverlay(QPixmap& pixmap);
    // ç»˜åˆ¶ç®­å¤´
    void drawArrow(QPainter& painter, const QPoint& start, const QPoint& end);

    QImage matToQImage(const cv::Mat& mat);
    // è®°å½•çŸ«æ­£æ•°æ®

    void recordCorrectionData(const cv::Point2f& rawOffset, const cv::Point2f& smoothedOffset);

    void setCorrectionParameters(double gainFactor, double maxOffset,
                                 double deadZone, double smoothingFactor);

    void enableCorrection(bool enable);

    void startRealNystagmusSimulation() ;

    void stopRealNystagmusSimulation();

    void outputNystagmusSimulationStats();

    void processNystagmusSimulation(const cv::Point2f &currentGazePoint, int frameId);
    void processNormalCorrection(const cv::Point2f &gazePoint, const cv::Point2f &predictedPoint, int frameId);

    void applyNystagmusDisplacement(const cv::Point2f &gazeOffset);
    void applyGazeBasedDisplacement(const cv::Mat& inputImage, cv::Mat& outputImage, const cv::Point2f& gazeOffset);
    void addNystagmusSimulationOverlay(cv::Mat& image, const cv::Point2f& gazeOffset);
    void drawHorizontalGazeOffsetTrajectory(cv::Mat& image, int centerX, int centerY) ;
    void drawGazeOffsetTrajectory(cv::Mat& image, int centerX, int centerY);
    void displayNystagmusImage(const cv::Mat& displacedImage, const cv::Point2f& gazeOffset);
    void addQtNystagmusOverlay(QPixmap& pixmap, const cv::Point2f& gazeOffset);
    void outputRealTimeNystagmusStats(const cv::Point2f& currentGaze, const cv::Point2f& offset, int frameId) ;

    bool isGazePointValid(const cv::Point2f& gazePoint);
    cv::Point2f getGazeOffsetFromImageCenter(const cv::Point2f& gazePoint) ;

    void displayReferencePointInfo();

    void visualizeDisplacement(cv::Mat& image, const cv::Point2f& displacement, const QString& mode);

    cv::Point2f applyAsymmetryCorrection(const cv::Point2f& basePrediction,
                                         const cv::Point2f& currentMeasurement,
                                         int frameId) ;
    bool detectSimplePeak(const cv::Point2f& currentGazePoint, int frameId);
    void initializeDefaultMappingCoefficients();
    void printceCoefficient(const std::vector<MappingCoefficients> &coeffs, const MappingCoefficients &coeff);

signals:
    void chartSignals();

private slots:
    void on_StarPushButton_clicked();
    void on_OutPushButton_clicked();
    void on_OutSavePushButton_clicked();
    void chartUpdates(const cv::Point2f& gazePoint, const cv::Point2f& predictedPoint, int frameId);


    void on_NystagmusSimulation_clicked();
    void on_StopPushButton_clicked();
};

#endif // EYETRACK_H

#ifndef VIDEOCAPTUREPIP_H
#define VIDEOCAPTUREPIP_H


#include <opencv2/opencv.hpp>
#include <pipline.h>
#include <qlabel.h>
#include "QFileDialog"
#include <QMutex>
#include <QTimer>
#include <QElapsedTimer>
#include "sharedpipelinedate.h"

extern "C" {
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libavutil/avutil.h>
#include <libavutil/imgutils.h>
#include <libswresample/swresample.h>
#include <libavfilter/avfilter.h>
#include <libswscale/swscale.h>
#include <libavdevice/avdevice.h>
}

class videoCapturePip: public QObject, public AbstractPipe
{
    Q_OBJECT
public:
    videoCapturePip():QObject(),AbstractPipe("videoCapturePipi", PIPE_SOURCE_E),
        sourceType(0), cameraIndex(0),
        m_width(1280), m_height(720), m_fps(60),
        m_isFrameReady(false), m_formatContext(nullptr), m_codecContext(nullptr),
        m_codec(nullptr), m_frame(nullptr), m_frameRGB(nullptr),
        m_packet(nullptr), m_swsContext(nullptr), m_buffer(nullptr),
        m_videoStreamIndex(-1), m_isopened(false)
    {
        avdevice_register_all();
        m_performanceTimer.start();
    }


    ~videoCapturePip(){
        resetSource();
    }

    void setSource(int type, const QVariant & source){
        sourceType = type;
        m_source = source;
    }

    // è®¾ç½®åˆ†è¾¨ç‡
    void setResolution(int width, int height){
        m_width = width;
        m_height = height;
    }

    // è®¾ç½®å¸§ç‡
    void setFrameRate(double fps){
        m_fps = fps;
    }

    void resetSource(){
        cleanup();
        qDebug()<<"è§†é¢‘æºæ¸…ç†å®Œæ¯•";
    }
    void closeCamera() {
        qDebug() << "å¼€å§‹å…³é—­æ‘„åƒå¤´æµç¨‹...";

        // è®¾ç½®å…³é—­æ ‡å¿—ï¼Œè®© pipe çº¿ç¨‹åœæ­¢è¯»å–
        m_shouldClose = true;

        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿ readFrame ä¸å†è¢«è°ƒç”¨
        std::this_thread::sleep_for(std::chrono::milliseconds(200));

        // ç°åœ¨å®‰å…¨åœ°å…³é—­èµ„æº
        QMutexLocker locker(&m_mutex);

        if (m_isopened) {
            qDebug() << "æ­£åœ¨å…³é—­" << (sourceType == 0 ? "æ‘„åƒå¤´" : "è§†é¢‘æ–‡ä»¶");

            // æ ‡è®°ä¸ºæœªæ‰“å¼€çŠ¶æ€
            m_isopened = false;

            // åˆ·æ–°è§£ç å™¨ç¼“å†²åŒº
            if (m_codecContext) {
                avcodec_send_packet(m_codecContext, nullptr);
                AVFrame* tmpFrame = av_frame_alloc();
                while (avcodec_receive_frame(m_codecContext, tmpFrame) == 0) {
                    // æ¸…ç©ºè§£ç å™¨ä¸­çš„æ‰€æœ‰å¸§
                }
                av_frame_free(&tmpFrame);
            }

            // é‡Šæ”¾è§£ç ç›¸å…³èµ„æº
            if (m_swsContext) {
                sws_freeContext(m_swsContext);
                m_swsContext = nullptr;
            }

            if (m_buffer) {
                av_free(m_buffer);
                m_buffer = nullptr;
            }

            if (m_frameRGB) {
                av_frame_free(&m_frameRGB);
                m_frameRGB = nullptr;
            }

            if (m_frame) {
                av_frame_free(&m_frame);
                m_frame = nullptr;
            }

            if (m_packet) {
                av_packet_free(&m_packet);
                m_packet = nullptr;
            }

            if (m_codecContext) {
                avcodec_free_context(&m_codecContext);
                m_codecContext = nullptr;
            }

            if (m_formatContext) {
                // å¯¹äºæ‘„åƒå¤´ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                if (sourceType == 0) {
                    // å…ˆåœæ­¢æ•°æ®æµ
                    av_read_pause(m_formatContext);
                }
                avformat_close_input(&m_formatContext);
                m_formatContext = nullptr;
            }

            // é‡ç½®å…¶ä»–çŠ¶æ€
            m_videoStreamIndex = -1;
            m_currentFrame.release();
            m_isFrameReady = false;

            qDebug() << (sourceType == 0 ? "æ‘„åƒå¤´" : "è§†é¢‘æ–‡ä»¶") << "èµ„æºå·²é‡Šæ”¾";
        }

        // é‡ç½®å…³é—­æ ‡å¿—
        m_shouldClose = false;

// Windowsä¸‹é¢å¤–ç­‰å¾…ï¼Œç¡®ä¿è®¾å¤‡å®Œå…¨é‡Šæ”¾
#ifdef _WIN32
        if (sourceType == 0) {
            std::this_thread::sleep_for(std::chrono::milliseconds(500));
        }
#endif

        qDebug() << "æ‘„åƒå¤´å…³é—­æµç¨‹å®Œæˆ";
    }



    bool isCameraOpened() const {
        QMutexLocker locker(&m_mutex);
        return m_isopened;
    }

    //å…ˆå…³é—­å½“å‰æ‘„åƒå¤´ï¼Œç„¶åé‡æ–°åˆå§‹åŒ–

    bool reopenCamera() {
        closeCamera();

        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿èµ„æºå®Œå…¨é‡Šæ”¾
        std::this_thread::sleep_for(std::chrono::milliseconds(100));

        return initializeFFmpeg();
    }
    bool initializeFFmpeg(){
        QMutexLocker locker(&m_mutex);

        if(sourceType == 0) {
            // æ‘„åƒå¤´æ¨¡å¼ - MJPEGä¸“ç”¨è®¾ç½®
            const AVInputFormat *inputFormat = av_find_input_format("dshow");
            if(!inputFormat){
                qDebug() << "æ‰¾ä¸åˆ°æ‘„åƒå¤´æ ¼å¼";
                return false;
            }

            QString deviceName = QString("video=%1").arg(m_source.toString());

            // MJPEGä¸“ç”¨å‚æ•°è®¾ç½®
            AVDictionary * options = nullptr;
            av_dict_set(&options, "video_size",
                        QString("%1x%2").arg(m_width).arg(m_height).toLocal8Bit().data(), 0);

            // å¼ºåˆ¶ä½¿ç”¨MJPEGï¼Œè¿™æ˜¯å…³é”®
            av_dict_set(&options, "vcodec", "mjpeg", 0);

            // MJPEGä¸“ç”¨ç¼“å†²åŒºè®¾ç½® - éœ€è¦è¶³å¤Ÿå¤§æ¥å¤„ç†é«˜è´¨é‡JPEGå¸§
            av_dict_set(&options, "rtbufsize", "5M", 0);      // å‡å°ç¼“å†²åŒºåˆ°5M
            av_dict_set(&options, "buffer_size", "2M", 0);    // é¢å¤–ç¼“å†²åŒºæ§åˆ¶
            av_dict_set(&options, "fflags", "+nobuffer+flush_packets", 0);  // ç¦ç”¨å†…éƒ¨ç¼“å†²
            av_dict_set(&options, "flags", "+low_delay", 0);  // ä½å»¶è¿Ÿæ¨¡å¼

            // å…¶ä»–è®¾ç½®ä¹Ÿè°ƒæ•´ä¸ºæ›´æ¿€è¿›çš„ä½å»¶è¿Ÿé…ç½®ï¼š
            av_dict_set(&options, "probesize", "1M", 0);           // ä»10Må‡å°åˆ°1M
            av_dict_set(&options, "analyzeduration", "500000", 0); // ä»2ç§’å‡å°åˆ°0.5ç§’
            av_dict_set(&options, "max_delay", "100000", 0);       // ä»0.5ç§’å‡å°åˆ°0.1ç§’

            qDebug() << "ğŸ”§ ä½¿ç”¨å°ç¼“å†²åŒºé…ç½® - rtbufsize: 5M, buffer_size: 2M";


            qDebug() << "æ‰“å¼€MJPEGæ‘„åƒå¤´" << deviceName;
            qDebug() << "å‚æ•°ï¼š" << m_width << "x" << m_height << "@" << m_fps << "fps";

            int ret = avformat_open_input(&m_formatContext,
                                          deviceName.toLocal8Bit().data(),
                                          inputFormat,
                                          &options);
            av_dict_free(&options);

            if(ret < 0){
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret, errbuf, AV_ERROR_MAX_STRING_SIZE);
                qDebug() << "æ— æ³•æ‰“å¼€æ‘„åƒå¤´:" << errbuf;
                cleanup();
                return false;
            }
        } else {
            // æ–‡ä»¶æ¨¡å¼ä¿æŒä¸å˜
            QString filePath = m_source.toString();
            int ret = avformat_open_input(&m_formatContext, filePath.toLocal8Bit().data(), nullptr, nullptr);
            if(ret < 0){
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret, errbuf, AV_ERROR_MAX_STRING_SIZE);
                qDebug() << "æ— æ³•æ‰“å¼€æ–‡ä»¶:" << errbuf;
                cleanup();
                return false;
            }
            qDebug() << "æ‰“å¼€æ–‡ä»¶æˆåŠŸ:" << filePath;
        }

        // æŸ¥æ‰¾æµä¿¡æ¯
        int ret = avformat_find_stream_info(m_formatContext, nullptr);
        if(ret < 0){
            qDebug() << "æ— æ³•è·å–æµä¿¡æ¯";
            cleanup();
            return false;
        }

        // æŸ¥æ‰¾è§†é¢‘æµ
        m_videoStreamIndex = -1;
        for(unsigned int i = 0; i < m_formatContext->nb_streams; i++){
            if(m_formatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO){
                m_videoStreamIndex = i;
                break;
            }
        }
        if(m_videoStreamIndex == -1){
            qDebug() << "æœªæ‰¾åˆ°è§†é¢‘æµ";
            cleanup();
            return false;
        }

        // è·å–è§£ç å™¨ - MJPEGä¸“ç”¨è®¾ç½®
        AVCodecParameters *codecpar = m_formatContext->streams[m_videoStreamIndex]->codecpar;
        m_codec = (AVCodec *)avcodec_find_decoder(codecpar->codec_id);
        if(!m_codec){
            qDebug() << "æœªæ‰¾åˆ°è§£ç å™¨";
            cleanup();
            return false;
        }

        // åˆ›å»ºè§£ç å™¨ä¸Šä¸‹æ–‡
        m_codecContext = avcodec_alloc_context3(m_codec);
        if(!m_codecContext){
            qDebug() << "æ— æ³•åˆ†é…è§£ç å™¨ä¸Šä¸‹æ–‡";
            cleanup();
            return false;
        }

        // å¤åˆ¶å‚æ•°
        avcodec_parameters_to_context(m_codecContext, codecpar);

        // MJPEGè§£ç å™¨ä¸“ç”¨è®¾ç½®
        m_codecContext->thread_count = 4;  // å¢åŠ çº¿ç¨‹æ•°å¤„ç†MJPEG
        m_codecContext->thread_type = FF_THREAD_FRAME;  // åªç”¨å¸§çº¿ç¨‹ï¼Œé¿å…ç‰‡çº¿ç¨‹é—®é¢˜

        // MJPEGé”™è¯¯å¤„ç†è®¾ç½®
        m_codecContext->error_concealment = FF_EC_GUESS_MVS | FF_EC_DEBLOCK;  // é”™è¯¯æ©ç›–
        m_codecContext->skip_frame = AVDISCARD_DEFAULT;  // ä¸è·³è¿‡å¸§
        m_codecContext->skip_idct = AVDISCARD_DEFAULT;   // ä¸è·³è¿‡IDCT
        m_codecContext->skip_loop_filter = AVDISCARD_DEFAULT;  // ä¸è·³è¿‡ç¯è·¯æ»¤æ³¢

        // MJPEGé”™è¯¯å¤„ç†è®¾ç½®ï¼ˆç§»é™¤è¿‡æ—¶çš„æ ‡å¿—ï¼‰
        m_codecContext->flags2 |= AV_CODEC_FLAG2_FAST;     // å¿«é€Ÿæ¨¡å¼
        m_codecContext->flags2 |= AV_CODEC_FLAG2_SHOW_ALL; // æ˜¾ç¤ºæ‰€æœ‰å¸§ï¼ŒåŒ…æ‹¬æŸåçš„

        // è®¾ç½®é”™è¯¯å®¹å¿åº¦
        m_codecContext->err_recognition = AV_EF_IGNORE_ERR; // å¿½ç•¥é”™è¯¯ç»§ç»­è§£ç 

        ret = avcodec_open2(m_codecContext, m_codec, nullptr);
        if(ret < 0){
            qDebug() << "æ— æ³•æ‰“å¼€è§£ç å™¨";
            cleanup();
            return false;
        }

        // åˆ†é…å¸§å’Œæ•°æ®åŒ…
        m_frame = av_frame_alloc();
        m_frameRGB = av_frame_alloc();
        m_packet = av_packet_alloc();

        if(!m_frame || !m_frameRGB || !m_packet){
            qDebug() << "æ— æ³•åˆ†é…å¸§å†…å­˜";
            cleanup();
            return false;
        }

        // è®¡ç®—ç°åº¦å¸§ç¼“å†²åŒºå¤§å°
        int numBytes = av_image_get_buffer_size(AV_PIX_FMT_GRAY8,
                                                m_codecContext->width,
                                                m_codecContext->height, 1);
        m_buffer = (uint8_t *)av_malloc(numBytes * sizeof(uint8_t));

        // è®¾ç½®ç°åº¦å¸§æ•°æ®æŒ‡é’ˆ
        av_image_fill_arrays(m_frameRGB->data, m_frameRGB->linesize, m_buffer,
                             AV_PIX_FMT_GRAY8, m_codecContext->width, m_codecContext->height, 1);

        // åˆå§‹åŒ–è½¬æ¢ä¸Šä¸‹æ–‡ - MJPEGä¸“ç”¨
        m_swsContext = sws_getContext(
            m_codecContext->width, m_codecContext->height, m_codecContext->pix_fmt,
            m_codecContext->width, m_codecContext->height, AV_PIX_FMT_GRAY8,
            SWS_BILINEAR | SWS_ACCURATE_RND,  // é«˜è´¨é‡è½¬æ¢
            nullptr, nullptr, nullptr);

        // MJPEGè‰²å½©ç©ºé—´è®¾ç½® - ä¸“é—¨å¤„ç†YUVJ422P
        if (m_swsContext) {
            // MJPEGé€šå¸¸ä½¿ç”¨JPEGè‰²å½©ç©ºé—´ï¼Œå…¨èŒƒå›´YUV
            int srcRange = 1;  // JPEGä½¿ç”¨å…¨èŒƒå›´ (0-255)
            int dstRange = 1;  // ç°åº¦è¾“å‡ºä¹Ÿä½¿ç”¨å…¨èŒƒå›´

            // MJPEGé€šå¸¸ä½¿ç”¨BT.601è‰²å½©çŸ©é˜µ
            const int* coefs = sws_getCoefficients(SWS_CS_ITU601);

            int colorResult = sws_setColorspaceDetails(m_swsContext,
                                                       coefs, srcRange,
                                                       coefs, dstRange,
                                                       0, 1 << 16, 1 << 16);
            if (colorResult >= 0) {
                qDebug() << "MJPEGè‰²å½©ç©ºé—´è®¾ç½®æˆåŠŸ";
            } else {
                qDebug() << "MJPEGè‰²å½©ç©ºé—´è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤";
            }
        }

        if(!m_swsContext){
            qDebug() << "æ— æ³•åˆå§‹åŒ–å›¾åƒè½¬æ¢ä¸Šä¸‹æ–‡";
            cleanup();
            return false;
        }

        m_isopened = true;
        qDebug() << "MJPEGåˆå§‹åŒ–æˆåŠŸ";

        AVRational frameRate = m_formatContext->streams[m_videoStreamIndex]->r_frame_rate;
        if(frameRate.den != 0) {
            double actualFrameRate = (double)frameRate.num / frameRate.den;
            qDebug() << "å®é™…å¸§ç‡" << actualFrameRate << "fps";
        }
        qDebug() << "åƒç´ æ ¼å¼" << av_get_pix_fmt_name(m_codecContext->pix_fmt);

        return true;
    }


    cv::Mat readFrame(){
        if (!m_isopened || m_shouldClose) {
            return cv::Mat();
        }

        if (!m_mutex.tryLock()) {
            return cv::Mat();
        }

        struct LockGuard {
            QMutex* mutex;
            LockGuard(QMutex* m) : mutex(m) {}
            ~LockGuard() { if (mutex) mutex->unlock(); }
        } lockGuard(&m_mutex);

        // æ·»åŠ è¯¦ç»†çš„æ—¶é—´æµ‹é‡
        QElapsedTimer totalTimer, readTimer, decodeTimer, convertTimer;
        totalTimer.start();

        // ç»Ÿè®¡å˜é‡ï¼ˆé™æ€ä»¥ä¾¿è·¨å¸§ç»Ÿè®¡ï¼‰
        static double totalReadTime = 0;
        static double totalDecodeTime = 0;
        static double totalConvertTime = 0;
        static int frameCount = 0;
        static int cacheHits = 0;  // ç¼“å†²åŒºå‘½ä¸­æ¬¡æ•°

        int maxAttempts = (sourceType == 0) ? 20 : 5;
        bool isVideoFile = (sourceType == 1);

        for(int attempts = 0; attempts < maxAttempts; attempts++) {
            readTimer.start();
            int ret = av_read_frame(m_formatContext, m_packet);
            double readTime = readTimer.nsecsElapsed() / 1e6;

            // åˆ¤æ–­æ˜¯å¦ä»ç¼“å†²åŒºè¯»å–ï¼ˆè¯»å–æ—¶é—´ç‰¹åˆ«çŸ­ï¼‰
            if (readTime < 0.5) {
                cacheHits++;
            }

            if(ret < 0){
                if(ret == AVERROR_EOF && isVideoFile){
                    qDebug() << "è§†é¢‘æ–‡ä»¶ç»“æŸï¼Œé‡æ–°å¼€å§‹æ’­æ”¾";
                    avcodec_flush_buffers(m_codecContext);
                    int seekRet = avformat_seek_file(m_formatContext, -1,
                                                     INT64_MIN, 0, INT64_MAX,
                                                     AVSEEK_FLAG_BACKWARD);
                    if (seekRet < 0) {
                        QString filePath = m_source.toString();
                        cleanup();
                        std::this_thread::sleep_for(std::chrono::milliseconds(100));
                        if (!initializeFFmpeg()) {
                            return cv::Mat();
                        }
                    }
                    std::this_thread::sleep_for(std::chrono::milliseconds(50));
                    continue;
                } else if (ret == AVERROR(EAGAIN)) {
                    std::this_thread::sleep_for(std::chrono::microseconds(500));
                    continue;
                } else {
                    if (attempts < maxAttempts - 1) {
                        std::this_thread::sleep_for(std::chrono::milliseconds(10));
                        continue;
                    } else {
                        return cv::Mat();
                    }
                }
            }

            if(m_packet->stream_index != m_videoStreamIndex){
                av_packet_unref(m_packet);
                continue;
            }

            // è§£ç è®¡æ—¶
            decodeTimer.start();
            ret = avcodec_send_packet(m_codecContext, m_packet);
            if(ret < 0){
                av_packet_unref(m_packet);
                if (ret == AVERROR(EAGAIN)) {
                    AVFrame* tempFrame = av_frame_alloc();
                    if (tempFrame) {
                        while (avcodec_receive_frame(m_codecContext, tempFrame) == 0) {
                        }
                        av_frame_free(&tempFrame);
                    }
                    continue;
                }
                continue;
            }

            ret = avcodec_receive_frame(m_codecContext, m_frame);
            double decodeTime = decodeTimer.nsecsElapsed() / 1e6;

            if(ret == 0){
                if (m_frame->width <= 0 || m_frame->height <= 0) {
                    av_packet_unref(m_packet);
                    continue;
                }

                // è½¬æ¢è®¡æ—¶
                convertTimer.start();
                int scaleResult = sws_scale(m_swsContext,
                                            (uint8_t const * const *)m_frame->data,
                                            m_frame->linesize,
                                            0,
                                            m_codecContext->height,
                                            m_frameRGB->data,
                                            m_frameRGB->linesize);

                double convertTime = convertTimer.nsecsElapsed() / 1e6;

                if (scaleResult <= 0) {
                    av_packet_unref(m_packet);
                    continue;
                }

                cv::Mat grayFrame(m_codecContext->height, m_codecContext->width, CV_8UC1,
                                  m_frameRGB->data[0], m_frameRGB->linesize[0]);

                if (grayFrame.empty()) {
                    av_packet_unref(m_packet);
                    continue;
                }

                // ç»Ÿè®¡
                totalReadTime += readTime;
                totalDecodeTime += decodeTime;
                totalConvertTime += convertTime;
                frameCount++;

                // æ¯100å¸§è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
                if (frameCount % 100 == 0) {
                    double avgRead = totalReadTime / frameCount;
                    double avgDecode = totalDecodeTime / frameCount;
                    double avgConvert = totalConvertTime / frameCount;
                    double cacheHitRate = (double)cacheHits / frameCount * 100;

                    // é‡ç½®ç»Ÿè®¡
                    totalReadTime = 0;
                    totalDecodeTime = 0;
                    totalConvertTime = 0;
                    frameCount = 0;
                    cacheHits = 0;
                }

                cv::Mat result = grayFrame.clone();
                av_packet_unref(m_packet);

                double totalTime = totalTimer.nsecsElapsed() / 1e6;

                return result;
            }
            else if(ret == AVERROR(EAGAIN)) {
                av_packet_unref(m_packet);
                continue;
            }

            av_packet_unref(m_packet);
        }

        return cv::Mat();
    }


    void cleanup(){
        QMutexLocker locker(&m_mutex);
        if(m_swsContext){
            sws_freeContext(m_swsContext);
            m_swsContext = nullptr;
        }
        if(m_buffer){
            av_free(m_buffer);
            m_buffer = nullptr;
        }
        if(m_frameRGB){
            av_frame_free(&m_frameRGB);
        }
        if(m_frame){
            av_frame_free(&m_frame);
        }
        if(m_packet){
            av_packet_free(&m_packet);
        }
        if(m_codecContext){
            avcodec_free_context(&m_codecContext);
        }
        if(m_formatContext){
            avformat_close_input(&m_formatContext);
        }
        m_isopened = false;
    }

    void pipe(QSemaphore & inSem, QSemaphore & outSem){
        bool pauseLogShown = false;
        while(m_paused && !exit() && !m_shouldClose) {
            if (!pauseLogShown) {
                qDebug() << "ç®¡é“å¯åŠ¨æ—¶å³å¤„äºæš‚åœçŠ¶æ€ï¼Œå¼€å§‹ç¼“å†²åŒºç®¡ç†...";
                pauseLogShown = true;
            }

            // å³ä½¿åœ¨åˆå§‹åŒ–ä¹‹å‰ä¹Ÿè¦å°è¯•æ¸…ç†ï¼ˆå¦‚æœæ‘„åƒå¤´å·²æ‰“å¼€ï¼‰
            handlePauseBufferManagement();
            std::this_thread::sleep_for(std::chrono::milliseconds(30));
        }

        if (pauseLogShown) {
            qDebug() << "ğŸ”§ ç®¡é“ä»æš‚åœçŠ¶æ€æ¢å¤ï¼Œç»§ç»­æ­£å¸¸æµç¨‹";
        }

        if (m_shouldClose || exit()) {
            return;
        }

        if(!initializeFFmpeg()){
            qDebug() << "åˆå§‹åŒ–å¤±è´¥";
            return;
        }

        static const cv::Rect roi(0, 0, 800, 720);
        FrameImage* pOutFrame = (FrameImage*)m_pOutImage;
        int frameId = 0;

        // åŒºåˆ†æ‘„åƒå¤´å’Œè§†é¢‘æ–‡ä»¶çš„å¸§ç‡æ§åˆ¶å‚æ•°
        bool isVideoFile = (sourceType == 1);
        bool isCamera = (sourceType == 0);

        const int FILE_TARGET_FPS = 60;
        const double FILE_INTERVAL_MS = 1000.0 / FILE_TARGET_FPS;
        auto lastFrameTime = std::chrono::high_resolution_clock::now();
        bool isFirstFrame = true;

        const int TARGET_FPS = 60;
        const double TARGET_INTERVAL_MS = 1000.0 / TARGET_FPS;
        auto startTime = std::chrono::high_resolution_clock::now();

        int maxFailures = isCamera ? 50 : 10;
        int consecutiveFailures = 0;
        int totalFrames = 0;
        int successfulFrames = 0;

        // æ·»åŠ æ€§èƒ½ç»Ÿè®¡å˜é‡
        double totalProcessingTime = 0;
        double totalReadTime = 0;
        double totalWaitTime = 0;
        int statFrameCount = 0;

        qDebug() << "å¼€å§‹å¤„ç†" << (isVideoFile ? "è§†é¢‘æ–‡ä»¶" : "æ‘„åƒå¤´")
                 << "ç›®æ ‡å¸§ç‡:" << (isVideoFile ? FILE_TARGET_FPS : TARGET_FPS) << "fps";

        while (!exit() && !m_shouldClose) {
            QElapsedTimer completeLoopTimer;
            completeLoopTimer.start();

            // æ·»åŠ å¤„ç†æ—¶é—´è®¡æ—¶å™¨
            QElapsedTimer processingTimer;
            double waitTimeMs = 0;

            if(m_isopened && !m_shouldClose){
                // æš‚åœå¤„ç†é€»è¾‘
                bool wasPaused = false;
                while(m_paused && !exit() && !m_shouldClose) {
                    if (!wasPaused) {
                        wasPaused = true;
                    }

                    // æš‚åœæœŸé—´ç§¯ææ¸…ç†ç¼“å†²åŒº
                    handlePauseBufferManagement();

                    std::this_thread::sleep_for(std::chrono::milliseconds(20));
                }
                if (wasPaused) {
                    // é‡ç½®æ—¶é—´æ§åˆ¶å’Œç»Ÿè®¡æ•°æ®
                    if (isVideoFile) {
                        lastFrameTime = std::chrono::high_resolution_clock::now();
                        isFirstFrame = true;
                    } else {
                        startTime = std::chrono::high_resolution_clock::now();
                    }
                    totalFrames = 0;
                    successfulFrames = 0;
                    consecutiveFailures = 0;

                    // é‡ç½®æ€§èƒ½ç»Ÿè®¡
                    totalProcessingTime = 0;
                    totalReadTime = 0;
                    totalWaitTime = 0;
                    statFrameCount = 0;
                }

                if(exit()) break;

                // å¸§ç‡æ§åˆ¶é€»è¾‘ - è®°å½•ç­‰å¾…æ—¶é—´
                QElapsedTimer waitTimer;
                waitTimer.start();

                if (isVideoFile) {
                    if (!isFirstFrame) {
                        auto currentTime = std::chrono::high_resolution_clock::now();
                        auto timeSinceLastFrame = std::chrono::duration_cast<std::chrono::microseconds>(
                            currentTime - lastFrameTime);

                        double elapsedMs = timeSinceLastFrame.count() / 1000.0;
                        if (elapsedMs < FILE_INTERVAL_MS) {
                            waitTimeMs = FILE_INTERVAL_MS - elapsedMs;
                            std::this_thread::sleep_for(std::chrono::microseconds((int)(waitTimeMs * 1000)));
                        }
                    } else {
                        isFirstFrame = false;
                    }
                } else if (isCamera) {
                    auto currentTime = std::chrono::high_resolution_clock::now();
                    auto elapsed = std::chrono::duration_cast<std::chrono::microseconds>(
                        currentTime - startTime);

                    int expectedFrames = (elapsed.count() / 1000.0) / TARGET_INTERVAL_MS;

                    if (totalFrames >= expectedFrames) {
                        waitTimeMs = TARGET_INTERVAL_MS - (elapsed.count() / 1000.0 - expectedFrames * TARGET_INTERVAL_MS);
                        if (waitTimeMs > 0) {
                            std::this_thread::sleep_for(std::chrono::microseconds((int)(waitTimeMs * 1000)));
                        }
                    }
                }

                double actualWaitTime = waitTimer.nsecsElapsed() / 1e6;
                totalWaitTime += actualWaitTime;

                // å¼€å§‹å®é™…å¤„ç†è®¡æ—¶
                processingTimer.start();

                // è¯»å–å¸§
                QElapsedTimer readTimer;
                readTimer.start();
                cv::Mat src = readFrame();

                double readTime = readTimer.nsecsElapsed() / 1e6;
                totalReadTime += readTime;

                totalFrames++;

                if(src.empty()){
                    consecutiveFailures++;

                    if (isVideoFile) {
                        qDebug() << "è§†é¢‘æ–‡ä»¶ç»“æŸï¼Œé‡æ–°å¼€å§‹æ’­æ”¾";
                        lastFrameTime = std::chrono::high_resolution_clock::now();
                        isFirstFrame = true;
                        consecutiveFailures = 0;
                        continue;
                    }

                    if (consecutiveFailures >= maxFailures) {
                        qDebug() << "è¿ç»­å¤±è´¥è¿‡å¤šï¼Œé‡æ–°åˆå§‹åŒ–";
                        cleanup();
                        std::this_thread::sleep_for(std::chrono::milliseconds(1000));

                        if (!initializeFFmpeg()) {
                            qDebug() << "é‡æ–°åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º";
                            break;
                        }

                        consecutiveFailures = 0;
                        totalFrames = 0;
                        successfulFrames = 0;

                        if (isCamera) {
                            startTime = std::chrono::high_resolution_clock::now();
                        } else {
                            lastFrameTime = std::chrono::high_resolution_clock::now();
                            isFirstFrame = true;
                        }
                        continue;
                    }

                    std::this_thread::sleep_for(std::chrono::microseconds(500));
                    continue;
                }

                // æˆåŠŸå¤„ç†å¸§
                consecutiveFailures = 0;
                successfulFrames++;

                frameId = SharedPipelineData::generateFrameId();

                // ROIå¤„ç†
                cv::Mat roiFrame;
                // if(src.cols > roi.x + roi.width && src.rows > roi.y + roi.height){
                    roiFrame = src(roi);
                // } else {
                //     qDebug()<<"è¾“å‡ºåŸå›¾";
                //     roiFrame = src;
                // }

                SharedPipelineData::createFrameData(frameId, roiFrame);
                pOutFrame->image = roiFrame.clone();
                pOutFrame->frameId = frameId;

                // æ›´æ–°æ—¶é—´è®°å½•
                if (isVideoFile) {
                    lastFrameTime = std::chrono::high_resolution_clock::now();
                }

                // è®¡ç®—å®é™…å¤„ç†æ—¶é—´ï¼ˆä¸åŒ…æ‹¬ç­‰å¾…ï¼‰
                double actualProcessingTime = processingTimer.nsecsElapsed() / 1e6;
                totalProcessingTime += actualProcessingTime;
                statFrameCount++;

                // å®Œæ•´å¾ªç¯æ—¶é—´
                double completeMs = completeLoopTimer.nsecsElapsed() / 1e6;

                // æ€§èƒ½ç»Ÿè®¡ - æ¯60å¸§è¾“å‡ºä¸€æ¬¡
                if (frameId % 60 == 0 && statFrameCount > 0) {
                    double avgProcessingTime = totalProcessingTime / statFrameCount;
                    double avgReadTime = totalReadTime / statFrameCount;
                    double avgWaitTime = totalWaitTime / statFrameCount;
                    double avgCompleteTime = avgProcessingTime + avgWaitTime;

                    qDebug() << QString("%1å¸§ %2 æ€§èƒ½ç»Ÿè®¡:").arg(isVideoFile ? "æ–‡ä»¶" : "æ‘„åƒå¤´").arg(frameId);
                    qDebug() << QString("  - å¹³å‡è¯»å–æ—¶é—´: %1 ms").arg(avgReadTime, 0, 'f', 2);
                    qDebug() << QString("  - å¹³å‡å¤„ç†æ—¶é—´: %1 ms (ä¸å«ç­‰å¾…)").arg(avgProcessingTime, 0, 'f', 2);
                    qDebug() << QString("  - å¹³å‡ç­‰å¾…æ—¶é—´: %1 ms").arg(avgWaitTime, 0, 'f', 2);
                    qDebug() << QString("  - å¹³å‡æ€»å¾ªç¯æ—¶é—´: %1 ms").arg(avgCompleteTime, 0, 'f', 2);
                    qDebug() << QString("  - å®é™…å¤„ç†FPS: %1").arg(1000.0 / avgProcessingTime, 0, 'f', 1);
                    qDebug() << QString("  - è¾“å‡ºFPS: %1").arg(1000.0 / avgCompleteTime, 0, 'f', 1);
                    qDebug() << QString("  - æˆåŠŸç‡: %1%").arg((double)successfulFrames/totalFrames*100, 0, 'f', 1);

                    // é‡ç½®ç»Ÿè®¡
                    totalProcessingTime = 0;
                    totalReadTime = 0;
                    totalWaitTime = 0;
                    statFrameCount = 0;
                }

                // ä¿å­˜å®é™…å¤„ç†æ—¶é—´ï¼ˆä¸åŒ…æ‹¬ç­‰å¾…ï¼‰åˆ°SharedPipelineData
                SharedPipelineData::setTime(frameId, 1, actualProcessingTime);

                outSem.release();
                sendOverSign(frameId);

            } else {
                if (m_shouldClose) break;
                qDebug() << "è§†é¢‘æºæœªæ‰“å¼€";
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
            }
        }

        if (!m_shouldClose) {
            resetSource();
        }
    }

    void forceCloseCamera() {

        // ç«‹å³è®¾ç½®æ‰€æœ‰æ ‡å¿—
        m_shouldClose = true;
        m_isopened = false;

        // ä¸ç­‰å¾…ï¼Œç›´æ¥æ¸…ç†
        cleanup();

// Windowsä¸‹ç­‰å¾…æ›´é•¿æ—¶é—´
#ifdef _WIN32
        std::this_thread::sleep_for(std::chrono::milliseconds(1000));
#endif

        m_shouldClose = false;
        qDebug() << "å¼ºåˆ¶å…³é—­å®Œæˆ";
    }
signals:
    void sendOverSign(int frameId);

private:
    int sourceType;  // 0: æ‘„åƒå¤´ 1:æ–‡ä»¶
    int cameraIndex; // æ‘„åƒå¤´ç´¢å¼•
    std::string filePath; // é€‰åˆ°çš„æ–‡ä»¶
    QVariant m_source;
    std::atomic<bool> m_shouldClose{false};  // æ·»åŠ å…³é—­æ ‡å¿—

    int m_width;  // åˆ†è¾¨ç‡å®½åº¦
    int m_height; // åˆ†è¾¨ç‡é«˜åº¦
    double m_fps; // å¸§ç‡

    // å¸§åŒæ­¥ç›¸å…³
    cv::Mat m_currentFrame;
    bool m_isFrameReady;
    QMutex m_frameMutex;

    // FFmpegç›¸å…³
    AVFormatContext *m_formatContext;
    AVCodecContext  *m_codecContext;
    int m_videoStreamIndex;
    AVCodec *m_codec;
    AVFrame *m_frame;
    AVFrame *m_frameRGB;
    AVPacket *m_packet;
    SwsContext *m_swsContext;
    uint8_t *m_buffer;
    bool m_isopened;

    // çº¿ç¨‹å®‰å…¨
    mutable  QMutex m_mutex;

    // æ€§èƒ½ç›‘æ§
    QElapsedTimer m_performanceTimer;


    void handlePauseBufferManagement(){
        static int clearCount = 0;
        static auto lastClearTime = std::chrono::high_resolution_clock::now();

        auto now = std::chrono::high_resolution_clock::now();
        auto timeSinceLastClear = std::chrono::duration_cast<std::chrono::milliseconds>(now - lastClearTime);

        // æ¯25msæ¸…ç†ä¸€æ¬¡ç¼“å†²åŒºï¼Œæ¯”è¾ƒé¢‘ç¹
        if (timeSinceLastClear.count() >= 25) {
            if (m_isopened && m_formatContext) {
                // ğŸ”§ å…³é”®ï¼šè¿ç»­è¯»å–å¤šå¸§å¿«é€Ÿæ¸…ç©ºç¼“å†²åŒº
                for (int i = 0; i < 5; ++i) {  // ä¸€æ¬¡è¯»å–æœ€å¤š5å¸§
                    cv::Mat discardFrame = readFrame();
                    if (discardFrame.empty()) {
                        break; // ç¼“å†²åŒºå·²ç©ºï¼Œé€€å‡ºå¾ªç¯
                    }
                    // ç«‹å³ä¸¢å¼ƒå¸§ï¼Œä¸åšä»»ä½•å¤„ç†
                }

                clearCount++;
                // æ¯éš”ä¸€æ®µæ—¶é—´è¾“å‡ºä¸€æ¬¡è°ƒè¯•ä¿¡æ¯ï¼Œé¿å…æ—¥å¿—åˆ·å±
                if (clearCount % 40 == 0) {
                    qDebug() << "ğŸ”§ ç¼“å†²åŒºæ¸…ç†è¿›è¡Œä¸­... å·²æ¸…ç†" << clearCount << "æ¬¡";
                }
            }
            lastClearTime = now;
        }
    };
};

#endif // VIDEOCAPTURE_H
